{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#Due to leftoevererrors in Nathan's python installation, some cleaning up occurs here\n",
    "#sys.path.append(\"./code/\")\n",
    "#sys.path.remove('/usr/local/lib/python2.7/site-packages') \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import datetime\n",
    "import pickle\n",
    "import gzip\n",
    "import os,glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import random\n",
    "from  scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "import itertools\n",
    "#sys.path\n",
    "\n",
    "\n",
    "import regex as re\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='juliettapc', api_key='nM6iUdx6dGaOiPXQTwpP')   # go to: https://plot.ly/settings/api#/   for a new key if needed\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                  \n",
    "\n",
    "####  NEW FILE INCLUDING EARLY CITATIONS OF YOUNG REFERENCES:   ../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit.pkl\n",
    "                                            \n",
    "#%time df_merged = pickle.load(open('../data/df_reference_cite_plos_merged_simplified_added_more_columns_no_self-cit_one_ref_per_sect_ONLY_ARTICLES.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "%time df_merged = pickle.load(open('../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit_and_after_accretion_time.pkl', 'rb'))\n",
    "print (\"done loading pickles\", df_merged.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_merged = df_merged[df_merged['cite_count'] != -1]   # i dont know why, but there are 7 occurrences with value -1\n",
    "\n",
    "\n",
    "\n",
    "plos_df = df_merged.drop_duplicates(subset=['paper_UT'])\n",
    "print (plos_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "####  FIGURE 4B:  histograms  NUMBER OF CIATIONS OF A PAPER VS # CITATIONS OF ITS YOUNGGGGG REFERENCES\n",
    "#### and NEW distplot (smoothing with kernel density estimation) with collapsed histograms of the same data\n",
    "\n",
    "\n",
    "\n",
    "string_top_bottom_plos  = 'bottom'  # top or bottom (plos papers)\n",
    "      \n",
    "\n",
    "years=[2011]      #[2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017] \n",
    "\n",
    "  \n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "string_isolated_ref = \"\"   #\"\"   #\"  #\"\"   # 0  or 1 (or empty string, to include all ref)\n",
    "string_self_ref =0         #\"\"      # \"\"   #1   # 0  or 1 (or empty string, to include all ref)   OJO!!! THIS NEW FILE DOES NOT INCLUDE SELF-CITATIONS TO BEGING WITH\n",
    "string_code_categ=\"\" #  ojo!!! the codes are strings, not integers. if i want to include multiple subjects:  \"1 2 8\"\n",
    "string_journal=\"\"#   PLOS ONE\"\n",
    "string_plos_field=\"\"#['D CU BIOLOGY']\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preselection_df = df_merged.drop_duplicates(subset=['paper_UT', 'reference_UT'])\n",
    "print (\"size of preselection (each ref. only used once per plos paper):\",preselection_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "##### preselection by plos year\n",
    "print (years)\n",
    "preselection_df = preselection_df[preselection_df['plos_pub_year'].isin(years)]  \n",
    "print (\"size of preselection1 (by plos years):\",preselection_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### i remove self-citations\n",
    "preselection_df = preselection_df[preselection_df['self_citation']== string_self_ref ]  \n",
    "print (\"size of preselection (no self-cit):\",preselection_df.shape)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "######### preselection by isolated or group references:\n",
    "if (string_isolated_ref==0) or  ( string_isolated_ref == 1 ): \n",
    "    preselection_df0 = preselection_df[preselection_df['isolated_citation']== string_isolated_ref ]  \n",
    "else:    \n",
    "    preselection_df0 = preselection_df   \n",
    "    print (\"size of preselection1 (by isolated/group ref):\",preselection_df0.shape, string_isolated_ref)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### preselection by plos ONE subject category:\n",
    "if string_code_categ==\"\": \n",
    "    preselection_df111 = preselection_df0\n",
    "else:    \n",
    "    if \" \" not in string_code_categ:  # to include one single category\n",
    "        preselection_df111 = preselection_df0[preselection_df0['categ_codes'].str.contains(string_code_categ)]        \n",
    "     \n",
    "    else:  # if multiple codes-categories\n",
    "        list_codes = string_code_categ.split(\" \")\n",
    "        \n",
    "\n",
    "        if len(list_codes) >= 2:              \n",
    "            preselection_df111 = preselection_df0[ preselection_df0['categ_codes'].str.contains('|'.join(list_codes)) ]  # to look for partial matches from a list of strings!!!!       \n",
    "\n",
    "\n",
    "    print (\" size of preselection (by plos ONE subject category):\",preselection_df111.shape, string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### preselection by plos journal:\n",
    "if string_journal==\"\": \n",
    "    preselection_df1 = preselection_df111\n",
    "else:    \n",
    "    preselection_df1 = preselection_df111[preselection_df111['plos_j1']== string_journal ]  \n",
    "print (\" size of preselection2 (by plos journal):\",preselection_df1.shape, string_journal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### preselection by plos field:\n",
    "if string_plos_field==\"\": \n",
    "    preselection_df2 = preselection_df1\n",
    "else:    \n",
    "    preselection_df2 = preselection_df1[preselection_df1['plos_field']== string_plos_field ]  \n",
    "print (\" size of preselection2 (by plos field):\",preselection_df2.shape, string_plos_field)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### i select only young ref!\n",
    "time_window = 1\n",
    "preselection_df3 = preselection_df2[preselection_df2['ref_pub_year'] >= (min(years)-time_window) ]   \n",
    "print (\" size of preselection3 (only young ref):\",preselection_df3.shape, \"   # unique plos papers:\", len(preselection_df3.paper_UT.unique()))\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print (\"\\nTot # records included:\",len(preselection_df3),\"   # plos papers:\",len(preselection_df3.paper_UT.unique()),\\\n",
    "#        \"   # unique ref:\", len(preselection_df3.reference_UT.unique()),'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "#### ojo!!! bins for plos on unique plos records\n",
    "df_plos = preselection_df3.drop_duplicates(subset=['paper_UT'])\n",
    "#list_q=[0.3,0.6,.9,.99,1]\n",
    "list_q=[0.1,0.6,.9,1]\n",
    "\n",
    "quantiles=sorted(list(df_plos['paper_cite_count'].quantile(list_q).to_dict().items())) #mean 10.68 \n",
    " \n",
    "# print (quantiles)   \n",
    "\n",
    "lista_bins_plos_citations=[]\n",
    "old_value=0\n",
    "for item in quantiles:\n",
    "    pair=[old_value, int(item[1])]\n",
    "    lista_bins_plos_citations.append(pair)\n",
    "    old_value = int(item[1])\n",
    "    \n",
    "# print (lista_bins_plos_citations)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "   \n",
    "list_subsets_data = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=4, vertical_spacing=0.001, horizontal_spacing=0.001)\n",
    "cont_columns =1\n",
    "\n",
    "list_median =[]\n",
    "list_mean =[]\n",
    "list_x_pos = []\n",
    "list_annot_x = []\n",
    "lista_x_series = []\n",
    "\n",
    "if string_top_bottom_plos  == 'top' :\n",
    "    \n",
    "    color_hist =' #4d88ff'\n",
    "    left_space = 200\n",
    "    \n",
    "    text_title = 'Top 10% papers'\n",
    "    list_x_pos = [132,165,130,173]\n",
    "    \n",
    "    text_y_axis=\"\"#Number citations <br>young references\"\n",
    "    \n",
    "    #### first, i select only the top-plos papers\n",
    "    item = lista_bins_plos_citations[-1]\n",
    "    \n",
    "    tot_minimo = item[0]\n",
    "    tot_maximo = item[1]\n",
    "\n",
    "    selection_df_top = preselection_df3[(preselection_df3['paper_cite_count'] >= tot_minimo)  &  (preselection_df3['paper_cite_count'] < tot_maximo)]\n",
    "\n",
    "  \n",
    "  \n",
    "    print (\"min, max in the top bin:\",selection_df_top.paper_cite_count.min(), selection_df_top.paper_cite_count.max())\n",
    "    \n",
    "    \n",
    "    ### i get 4 bins for the top-plos selection\n",
    "    df_top_plos_only = selection_df_top.drop_duplicates(subset=['paper_UT'])\n",
    "    \n",
    "    list_q=[0.25,.5,.75,1]\n",
    "\n",
    "    quantiles_top=sorted(list(df_top_plos_only['paper_cite_count'].quantile(list_q).to_dict().items())) #mean 10.68    \n",
    "    list_bins_histogr=[]\n",
    "    old_value=selection_df_top.paper_cite_count.min()\n",
    "    for item in quantiles_top:\n",
    "        pair=[old_value, int(item[1])]\n",
    "        list_bins_histogr.append(pair)\n",
    "        old_value = int(item[1])    \n",
    "    \n",
    "    print (string_top_bottom_plos, tot_minimo, tot_maximo, selection_df_top.shape, \" # plos\",   len(selection_df_top.paper_UT.unique()),\\\n",
    "             \" #ref:\",len(selection_df_top.reference_UT.unique()), \"bins within top-plos:\", list_bins_histogr)\n",
    "     \n",
    "        \n",
    "    \n",
    "\n",
    "    ## one histogram per bin of top-plos\n",
    "    for item in list_bins_histogr :\n",
    "\n",
    "        minimo = item[0]\n",
    "        maximo = item[1]\n",
    "        \n",
    "        etiqueta =str(item[0])+\"-\"+str(item[1]-1)+\" Citations\"  #str(item).replace(\"]\",'').replace(\"[\",'').replace(\", \",'-')+\" Citations\"\n",
    "        list_annot_x.append(etiqueta)# = ['00 Citations', '01 Citation','02 Citations','03 Citations']\n",
    "\n",
    "        df_selection = selection_df_top[(selection_df_top['paper_cite_count'] >= minimo)  &  (selection_df_top['paper_cite_count'] < maximo)]\n",
    "\n",
    "        y = df_selection['cite_count']\n",
    "        \n",
    "    \n",
    "        lista_x_series.append(y.tolist())\n",
    "        \n",
    "        \n",
    "        \n",
    "        trace1 = go.Histogram(\n",
    "                    y=y,\n",
    "                    name= str(minimo)+\"-\"+str(maximo)+ \" citations, N:\"+str(len(y)),                    \n",
    "                    ybins=dict(\n",
    "                           start=0,\n",
    "                           end=selection_df_top.cite_count.max(),\n",
    "                           size=10),\n",
    "                     marker=dict(\n",
    "                         color=color_hist ),                   \n",
    "            showlegend = False, \n",
    "                   )\n",
    "\n",
    "        fig.append_trace(trace1, 1, cont_columns)\n",
    "\n",
    "        cont_columns +=1\n",
    "\n",
    "        print (\"   bin:\",minimo, maximo, df_selection.shape, df_selection['cite_count'].mean(), df_selection['cite_count'].std())\n",
    "\n",
    "        list_median.append(df_selection.cite_count.median())\n",
    "        list_mean.append(df_selection.cite_count.mean())\n",
    "\n",
    "        list_subsets_data.append(list(df_selection.cite_count.values))\n",
    "\n",
    "\n",
    "elif string_top_bottom_plos  == 'bottom' :\n",
    "    \n",
    "    left_space = 350\n",
    "    \n",
    "    text_title = 'Bottom 10% papers'\n",
    "    list_annot_x = ['0 Citations', '1 Citation','2 Citations','3 Citations']\n",
    "    list_x_pos = [40,80,130,140]\n",
    "    \n",
    "    text_y_axis=\"Number of citations <br>of young references\"\n",
    "    \n",
    "    color_hist = '#ff4d4d'\n",
    "    \n",
    "    ### first i select the bottom plos papers\n",
    "    item = lista_bins_plos_citations[0]\n",
    "    \n",
    "    minimo = 0\n",
    "    maximo = 4\n",
    "\n",
    "    selection_df_bottom = preselection_df3[(preselection_df3['paper_cite_count'] >= minimo)  &  (preselection_df3['paper_cite_count'] < maximo)]\n",
    "\n",
    "    print (string_top_bottom_plos, minimo, maximo, \"  unique values in select\", selection_df_bottom['paper_cite_count'].unique(), selection_df_bottom.shape, \\\n",
    "           \" # plos:\",len(selection_df_bottom.paper_UT.unique()), \" # ref\",len(selection_df_bottom.reference_UT.unique()))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### then i get one histogram per value\n",
    "    for  value in range(4):#number of ciations of papers 0, 1,2,3, 4: #####################\n",
    "\n",
    "                \n",
    "\n",
    "        df_selection = selection_df_bottom[selection_df_bottom['paper_cite_count'] == value]   \n",
    "        y = df_selection['cite_count']\n",
    "\n",
    "        lista_x_series.append(y.tolist())\n",
    "        \n",
    "        trace1 = go.Histogram(\n",
    "                    y=y,\n",
    "                   # name= str(value)+ \" citations, N:\"+str(len(y)),\n",
    "                    ybins=dict(\n",
    "                           start=0,\n",
    "                           end=selection_df_bottom.cite_count.max(),\n",
    "                           size=10),\n",
    "                    marker=dict(\n",
    "                        color=color_hist,),                   \n",
    "            showlegend = False, \n",
    "           \n",
    "                )\n",
    "\n",
    "        fig.append_trace(trace1, 1, cont_columns)\n",
    "        cont_columns +=1\n",
    "\n",
    "        print (\"   bin:\",value, df_selection.shape, df_selection['cite_count'].mean(), df_selection['cite_count'].std())\n",
    "\n",
    "        \n",
    "        list_median.append(df_selection.cite_count.median())\n",
    "        list_mean.append(df_selection.cite_count.mean())\n",
    "        list_subsets_data.append(list(df_selection.cite_count.values))\n",
    "        \n",
    "#fig.layout.yaxis.update({'title':'Number of citations of young references'}) \n",
    "#fig.layout.xaxis3.update({'title':'Number of citations of papers') \n",
    "\n",
    "\n",
    "\n",
    "fig.layout.yaxis1.update({'range':[-5,450]})  \n",
    "fig.layout.yaxis2.update({'range':[-5,450]})  \n",
    "fig.layout.yaxis3.update({'range':[-5,450]})  \n",
    "fig.layout.yaxis4.update({'range':[-5,450]})  \n",
    "        \n",
    "    \n",
    "     \n",
    "    \n",
    "fig.layout.yaxis2.update({'showticklabels':False})     \n",
    "fig.layout.yaxis3.update({'showticklabels':False})     \n",
    "fig.layout.yaxis4.update({'showticklabels':False})        \n",
    "\n",
    "\n",
    "fig.layout.yaxis1.update({'gridwidth':5,'showgrid':True})       \n",
    "fig.layout.yaxis2.update({'gridwidth':5,'showgrid':True})     \n",
    "fig.layout.yaxis3.update({'gridwidth':5,'showgrid':True})     \n",
    "fig.layout.yaxis4.update({'gridwidth':5,'showgrid':True})  \n",
    "\n",
    "\n",
    "fig.layout.xaxis1.update({'showgrid':False})       \n",
    "fig.layout.xaxis2.update({'showgrid':False})     \n",
    "fig.layout.xaxis3.update({'showgrid':False})     \n",
    "fig.layout.xaxis4.update({'showgrid':False})   \n",
    "\n",
    "\n",
    "# layout = go.Layout(\n",
    "#     xaxis=dict( ticks='', showgrid=False, zeroline=False, nticks=20 ),\n",
    "\n",
    "\n",
    "\n",
    "fig.layout.update(\n",
    "    {\n",
    "   \n",
    "     'shapes': [\n",
    "        # Line Horizontal --  median\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_median[0],\n",
    "            'x1': list_x_pos[0]+7,\n",
    "            'y1': list_median[0],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "                \n",
    "            },\n",
    "        },\n",
    "      # Line Horizontal --  median\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x2',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_median[1],\n",
    "            'x1': list_x_pos[1]+7,\n",
    "            'y1': list_median[1],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "               \n",
    "            },\n",
    "        },\n",
    "        # Line Horizontal --  median\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x3',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_median[2],\n",
    "            'x1': list_x_pos[2]+15,\n",
    "            'y1': list_median[2],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "                \n",
    "            },\n",
    "        },\n",
    "      # Line Horizontal --  median\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x4',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_median[3],\n",
    "            'x1': list_x_pos[3]+15,\n",
    "            'y1': list_median[3],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "                \n",
    "            },\n",
    "        },  \n",
    "         \n",
    "         \n",
    "         \n",
    "         \n",
    "         \n",
    "          # Line Horizontal --  mean\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_mean[0],\n",
    "            'x1': list_x_pos[0]+7,\n",
    "            'y1': list_mean[0],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "                'dash': 'dot',\n",
    "            },\n",
    "        },\n",
    "      # Line Horizontal --  mean\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x2',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_mean[1],\n",
    "            'x1': list_x_pos[1]+7,\n",
    "            'y1': list_mean[1],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "                'dash': 'dot',\n",
    "            },\n",
    "        },\n",
    "        # Line Horizontal --  mean\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x3',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_mean[2],\n",
    "            'x1': list_x_pos[2]+15,\n",
    "            'y1': list_mean[2],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "                'dash': 'dot',\n",
    "            },\n",
    "        },\n",
    "      # Line Horizontal --  mean\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'x4',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': list_mean[3],\n",
    "            'x1': list_x_pos[3]+15,\n",
    "            'y1': list_mean[3],\n",
    "            'line': {\n",
    "                'color': 'rgb(0,0,0)',\n",
    "                'width': 8.5,\n",
    "                'dash': 'dot',\n",
    "            },\n",
    "        },  \n",
    "     \n",
    "     \n",
    "     \n",
    "     ]  ,\n",
    "        \n",
    "     'annotations' : [   \n",
    "         dict(  # title\n",
    "            x=.5,\n",
    "            y=1.3,  #1.15,\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text=text_title,\n",
    "            showarrow=False,  \n",
    "            font=dict(               \n",
    "                size=65,),\n",
    "           ),    \n",
    "         \n",
    "         \n",
    "         dict(  # this is for the xaxis label\n",
    "            x=.5,\n",
    "            y=-.25,\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text=\"Number of citations\",\n",
    "            showarrow=False,  \n",
    "            font=dict(               \n",
    "                size=65,),\n",
    "           ),    \n",
    "         \n",
    "         dict(  # this is for the yaxis label\n",
    "            x=-.2,\n",
    "            y=.5,\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text=text_y_axis,\n",
    "            showarrow=False, \n",
    "            textangle=-90,\n",
    "            font=dict(               \n",
    "                size=65,),\n",
    "           ),    \n",
    "         \n",
    "         \n",
    "         \n",
    "         \n",
    "         \n",
    "         \n",
    "          dict(\n",
    "            x=list_x_pos[0]/2.,\n",
    "            y=1.1, #-.15,\n",
    "            xref='x',\n",
    "            yref='paper',\n",
    "            text=list_annot_x[0],\n",
    "            showarrow=False,  \n",
    "              font=dict(               \n",
    "                size=40,),\n",
    "           ),    \n",
    "         \n",
    "          dict(\n",
    "            x=list_x_pos[1]/2.,\n",
    "            y=1.1, #-.15,\n",
    "            xref='x2',\n",
    "            yref='paper',\n",
    "            text=list_annot_x[1],\n",
    "            showarrow=False,\n",
    "              font=dict(               \n",
    "                size=40,),\n",
    "           ),    \n",
    "         \n",
    "          dict(\n",
    "            x=list_x_pos[2]/2.,\n",
    "            y=1.1, #-.15,\n",
    "            xref='x3',\n",
    "            yref='paper',\n",
    "            text=list_annot_x[2],\n",
    "            showarrow=False,\n",
    "              font=dict(               \n",
    "                size=40,),\n",
    "           ),    \n",
    "         \n",
    "          dict(\n",
    "            x=list_x_pos[3]/2.,\n",
    "            y=1.1, #-.15,\n",
    "            xref='x4',\n",
    "            yref='paper',\n",
    "            text=list_annot_x[3],\n",
    "            showarrow=False,\n",
    "              font=dict(               \n",
    "                size=40,),\n",
    "           ),    \n",
    "         \n",
    "         \n",
    "         \n",
    "         \n",
    "       ]\n",
    "                 \n",
    "                 \n",
    "                 \n",
    "    } )\n",
    "\n",
    "\n",
    "print (\"median:\",list_median)\n",
    "\n",
    "font_gral=35   # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "fig['layout']['font']['size'] = font_gral\n",
    "\n",
    "# fig['layout']['yaxis']['titlefont']['size'] = font_gral \n",
    "      \n",
    "\n",
    "\n",
    "fig['layout']['margin']=dict(\n",
    "        l=left_space,\n",
    "       # r=50,\n",
    "        b=200,\n",
    "        t=250,        \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename='testing_multiple_vertical_histogr' ,image_width=1800, image_height=1200, filename='../plots/testing_multiple_vertical_histogr.html', validate=True)\n",
    "\n",
    "###############################################\n",
    "###############################################\n",
    "###############################################\n",
    "###############################################\n",
    "###############################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_colors = ['#67a9cf','#91cf60','#f1a340','#d7191c']\n",
    "\n",
    "#list_colors = ['#a6611a','#dfc27d','#80cdc1','#018571']\n",
    "# if string_top_bottom_plos  == 'top' :\n",
    "#     list_colors = ['#bdd7e7','#6baed6','#3182bd','#08519c']\n",
    "# elif string_top_bottom_plos  == 'bottom' :\n",
    "#     list_colors = ['#fdcc8a','#fc8d59','#e34a33','#b30000']\n",
    "\n",
    "\n",
    "############  Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(lista_x_series, list_annot_x, bin_size=10,  show_hist=False,  show_rug=False, show_curve=True, colors =  list_colors)#,curve_type='lognormal')#, curve_type='kde', show_rug=False, bin_size=.2, , show_hist=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################  Layout\n",
    "\n",
    "\n",
    "fig['layout']['xaxis']['range'] = [1,500]  #[.001,3.5]  ## because the axis is log, the range needs to be in log units too! \n",
    "  \n",
    "#fig['layout']['xaxis']['tickvals'] =  [1, 10, 100, 1000,2000]   \n",
    " \n",
    "fig['layout']['xaxis']['title'] = \"Number of citations\"\n",
    "fig['layout']['yaxis']['title'] = \"Probability density\"\n",
    "fig['layout']['title'] = string_top_bottom_plos.capitalize()+\" 10% papers\"    \n",
    "      \n",
    "\n",
    "    \n",
    "    \n",
    "font_gral=50   # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "fig['layout']['font']['size'] = font_gral\n",
    "fig['layout']['xaxis']['titlefont']['size'] = font_gral \n",
    "fig['layout']['yaxis']['titlefont']['size'] = font_gral \n",
    "\n",
    "fig['layout']['legend']=dict( x=0.75, y=.9,  ) #font=dict(size=20) \n",
    "                           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig['layout']['margin']=dict(\n",
    "        l=250,\n",
    "        r=50,\n",
    "        b=150,\n",
    "        t=150,  \n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# Plot!\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename='multiple_distplot' ,image_width=1800, image_height=1200, filename='../plots/multiple_distplot.html', validate=True)\n",
    "\n",
    "### NOTE:  this figures is requires some touch up from the plotly platform (lines width cant be customized from here for some reason)\n",
    "\n",
    "##################################################3\n",
    "###################################################3\n",
    "\n",
    "#### run old Figure 4b cell first to get the list of values!!!!\n",
    "\n",
    "\n",
    "list_colors = ['#67a9cf','#91cf60','#f1a340','#d7191c']\n",
    "\n",
    "data = []\n",
    "for i in  range(len(lista_x_series)):\n",
    "    \n",
    "    a =  lista_x_series[i]\n",
    "    c = list_colors[i]\n",
    "    \n",
    "    ### equivalent to normalized cumulative distribution  !!!\n",
    "    x = np.sort(a)\n",
    "    y = np.linspace(0, 1, len(a), endpoint=False)\n",
    "    \n",
    "    \n",
    "    trace0 = go.Scatter(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        mode = 'lines',\n",
    "        name = list_annot_x[i],\n",
    "        marker = dict(         \n",
    "                color = c,\n",
    "                line = dict(\n",
    "                        width = 50,\n",
    "                        color = c\n",
    "                )\n",
    "            )\n",
    "    )\n",
    "\n",
    "    data.append(trace0)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "layout = Layout(    \n",
    "\n",
    "\n",
    "    xaxis=dict(\n",
    "        title= \"Number of citations received\",   \n",
    "#         titlefont=dict(\n",
    "#             #size=font_axes,\n",
    "#             color='black'),  \n",
    "#         tickfont=dict(   \n",
    "#             #family=font,\n",
    "#             size=font_ticks,\n",
    "#             color='black'),\n",
    "         #range = [1, 500],#range=[np.log10(0.1),np.log10(max_x)],   # because the axis is log, the range needs to be in log units too!  :(\n",
    "         type='log',            \n",
    "        ),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        title='Probability density',\n",
    "        #type='log',\n",
    "#         titlefont=dict(            \n",
    "#             size=font_axes,\n",
    "#             color='black'\n",
    "#         #    color='lightgrey'\n",
    "#         ),  \n",
    "#         tickfont=dict(   \n",
    "#             #family=font,\n",
    "#             size=font_ticks,\n",
    "#             color='black'\n",
    "#         ),\n",
    "        ),                \n",
    "\n",
    "\n",
    "\n",
    ")       \n",
    "\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "    \n",
    "fig['layout']['xaxis']['title'] = \"Number of citations\"\n",
    "fig['layout']['yaxis']['title'] = \"Cumulative probability density\"\n",
    "fig['layout']['title'] = string_top_bottom_plos.capitalize()+\" 10% papers\"    \n",
    "      \n",
    "\n",
    "    \n",
    "    \n",
    "font_gral=50   # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "fig['layout']['font']['size'] = font_gral\n",
    "fig['layout']['xaxis']['titlefont']['size'] = font_gral +10\n",
    "fig['layout']['yaxis']['titlefont']['size'] = font_gral +10\n",
    "\n",
    "fig['layout']['legend']=dict( x=0.75, y=.9,  ) #font=dict(size=20) \n",
    "                           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig['layout']['margin']=dict(\n",
    "        l=250,\n",
    "        r=50,\n",
    "        b=150,\n",
    "        t=150,  \n",
    "    )    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Plot!\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename='histogram_num_cit_ref_'+string_top_bottom_plos+str(10)+'_'+str(years[0]) ,image_width=1800, image_height=1200, filename='../plots/histogram.html', validate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################  MORE SOPHISTICATED RANDOMIZATION SCHEME: ALSO CONTROLING FOR PLOS FIELD  (AS WELL AS PLOS YEAR)  AND PRESERVING REFERENCES THAT ARE CITED TOGETHER IN A GROUP\n",
    "############################################## ####################### ####################### ####################### ####################### ####################### \n",
    "\n",
    "\n",
    "### Figure 4A\n",
    "\n",
    "\n",
    "\n",
    "#### (i compare the usage of top/nontop references by top/nontop plos papers with a null model that comes from randomizing the data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### (i compare the usafe of top/nontop references by top/nontop plos papers with a null model that comes from randomizing the data)\n",
    "\n",
    "Niter=1000\n",
    "\n",
    "list_list_years = [[2008],[2009],[2010],[2011],[2012],[2013],[2014]]\n",
    "\n",
    "#years=[2008]\n",
    "    \n",
    "for years in list_list_years:\n",
    "   \n",
    "\n",
    "    string_references_age=\"all\"   #young\"#old\"  # young # all   for the selection of what references i include\n",
    "    string_isolated_ref=\"\"  #\"\"   # 0  or 1 (or empty string, to include all ref)\n",
    "    string_self_ref=0    #\"\"#1   # 0  or 1 (or empty string, to include all ref)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### plos ONE categories. \n",
    "    string_code_categ=\"0\" #  ojo!!! the codes are strings, not integers. if i want to include multiple subjects:  \"1 2 8\"\n",
    "\n",
    "    #  '0': 'Biology and life sciences'             6,032,537\n",
    "    #  '1': 'Computer and information sciences'     1,207,799\n",
    "    #  '10': 'Social sciences'                      755,899\n",
    "    #  '2': 'Earth sciences'                        533,155\n",
    "    #  '3': 'Ecology and environmental sciences'    624,142\n",
    "    #  '4': 'Engineering and technology'            382,247 \n",
    "    #  '5': 'Medicine and health sciences'          4,535,926   \n",
    "    #  '6': 'People and places'                     691,523\n",
    "    #  '7': 'Physical sciences'                     2,100,827\n",
    "    #  '8': 'Research and analysis methods'         3,871,470\n",
    "    #  '9': 'Science policy'                        43,360 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # for string_code_categ in range(11):\n",
    "    #     string_code_categ = str(string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### plos journals \n",
    "    string_journal=\"\"\n",
    "\n",
    "        # PLOS ONE       6,367,070\n",
    "        # PLOS GENET      149,923\n",
    "        # PLO NE TR D     138,289   # (neglected tropical diseases)\n",
    "        # PLOS PATHOG     109,803\n",
    "        # PLOS COMPUT      77,924\n",
    "        # PLOS BIOL        56,754\n",
    "        # PLOS MED         24,506\n",
    "\n",
    "\n",
    "\n",
    "    ######### WoS subject categories. \n",
    "    string_plos_field=\"\"#['D CU BIOLOGY']\"\n",
    "\n",
    "    # ['D RO MULTIDISCIPLINARY SCIENCES']                                                                                                       4464540\n",
    "    # ['D CU BIOLOGY']                                                                                                                          1055045\n",
    "    # ['D RO MULTIDISCIPLINARY SCIENCES', 'D CU BIOLOGY']                                                                                        847485\n",
    "    # ['D KM GENETICS & HEREDITY']                                                                                                               149923\n",
    "    # ['D YU TROPICAL MEDICINE', 'D TI PARASITOLOGY']                                                                                            138289\n",
    "    # ['D ZE VIROLOGY', 'D QU MICROBIOLOGY', 'D TI PARASITOLOGY']                                                                                109803\n",
    "    # ['D CO BIOCHEMICAL RESEARCH METHODS', 'D MC MATHEMATICAL & COMPUTATIONAL BIOLOGY']                                                          77687\n",
    "    # ['D CQ BIOCHEMISTRY & MOLECULAR BIOLOGY', 'D CU BIOLOGY']                                                                                   56754\n",
    "    # ['D PY MEDICINE, GENERAL & INTERNAL']                                                                                                       24506\n",
    "    # ['D CO BIOCHEMICAL RESEARCH METHODS', 'D MC MATHEMATICAL & COMPUTATIONAL BIOLOGY', 'D PO MATHEMATICS, INTERDISCIPLINARY APPLICATIONS']        237\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"original size:\",df_merged.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### preselection by plos year\n",
    "    print (years)\n",
    "    preselection_df = df_merged[df_merged['plos_pub_year'].isin(years)]  \n",
    "    print (\"size of preselection1 (by plos years):\",preselection_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### i remove self-citations\n",
    "    if (string_self_ref==0) or  ( string_self_ref == 1 ): \n",
    "        preselection_df = preselection_df[preselection_df['self_citation']== string_self_ref ]  \n",
    "        if string_self_ref ==0:\n",
    "            string_self_ref = \", no self-cit\"\n",
    "        elif string_self_ref ==1:\n",
    "            string_self_ref = \", only self-cit\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by isolated or group references:\n",
    "    if (string_isolated_ref==0) or  ( string_isolated_ref == 1 ): \n",
    "        preselection_df0 = preselection_df[preselection_df['isolated_citation']== string_isolated_ref ]  \n",
    "\n",
    "        if string_isolated_ref ==0:\n",
    "            string_isolated_ref = \", group ref\"\n",
    "        elif string_isolated_ref ==1:\n",
    "            string_isolated_ref = \", isolated ref\"\n",
    "    else:    \n",
    "        preselection_df0 = preselection_df   \n",
    "        print (\"size of preselection1 (by isolated/group ref):\",preselection_df0.shape, string_isolated_ref)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by plos ONE subject category:\n",
    "    if string_code_categ==\"\": \n",
    "        preselection_df111 = preselection_df0\n",
    "    else:    \n",
    "        if \" \" not in string_code_categ:  # to include one single category\n",
    "            preselection_df111 = preselection_df0[preselection_df0['categ_codes'].str.contains(string_code_categ)]        \n",
    "            string_code_categ = \" \"+dict_code_categ[string_code_categ]  \n",
    "\n",
    "        else:  # if multiple codes-categories\n",
    "            list_codes = string_code_categ.split(\" \")\n",
    "            print (list_codes)\n",
    "\n",
    "            if len(list_codes) >= 2:              \n",
    "                preselection_df111 = preselection_df0[ preselection_df0['categ_codes'].str.contains('|'.join(list_codes)) ]  # to look for partial matches from a list of strings!!!!!\n",
    "\n",
    "\n",
    "            string_code_categ = \"\" \n",
    "            for code in list_codes:\n",
    "                string_code_categ += \"-\"+dict_code_categ[code] \n",
    "\n",
    "\n",
    "        print (\" size of preselection (by plos ONE subject category):\",preselection_df111.shape, string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by plos journal:\n",
    "    if string_journal==\"\": \n",
    "        preselection_df1 = preselection_df111\n",
    "    else:    \n",
    "        preselection_df1 = preselection_df111[preselection_df111['plos_j1']== string_journal ]  \n",
    "    print (\" size of preselection2 (by plos journal):\",preselection_df1.shape, string_journal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by plos field:\n",
    "    if string_plos_field==\"\": \n",
    "        preselection_df2 = preselection_df1\n",
    "    else:    \n",
    "        preselection_df2 = preselection_df1[preselection_df1['plos_field']== string_plos_field ]  \n",
    "    print (\" size of preselection2 (by plos field):\",preselection_df2.shape, string_plos_field)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### preselection only young/old references:       \n",
    "    preselection_df3 = preselection_df2\n",
    "    if string_references_age == \"young\":\n",
    "        time_window_age = 1   \n",
    "        preselection_df3 = preselection_df2[preselection_df2['ref_pub_year'] >= (min(years)-time_window_age) ]   \n",
    "\n",
    "        print (\"    size of preselection3 (only young references):\",preselection_df3.shape, string_references_age)\n",
    "\n",
    "    elif string_references_age == \"old\":\n",
    "        time_window_age = 10    \n",
    "        preselection_df3 = preselection_df2[preselection_df2['ref_pub_year'] <= (min(years)-time_window_age) ]   \n",
    "\n",
    "        print (\"    size of preselection3 (only old references):\",preselection_df3.shape,string_references_age )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    N_plos = len(preselection_df3.paper_UT.unique())         \n",
    "    N_ref = len(preselection_df3.reference_UT.unique()) \n",
    "    N_all = len(preselection_df3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"     N plos:\", N_plos,\"  N  ref:\",N_ref, \" N records:\", N_all)        \n",
    "\n",
    "\n",
    "\n",
    "    preselection_df3 = preselection_df3.drop_duplicates(subset=['paper_UT', 'reference_UT'])\n",
    "\n",
    "    print (\"OJO!!! EACH REFERENCE ONLY COUNTED ONCE PER PAPER:\")\n",
    "\n",
    "    N_plos = len(preselection_df3.paper_UT.unique())         \n",
    "    N_ref = len(preselection_df3.reference_UT.unique()) \n",
    "    N_all = len(preselection_df3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"     N plos:\", N_plos,\"  N  ref:\",N_ref, \" N records:\", N_all)        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############## i define quantiles for plos papers (for that subselection, and based on their FINAL number of citations):\n",
    "    list_q_plos=[.1,.9,1]\n",
    "    #list_q_plos=[.05,.95,1]\n",
    "\n",
    "    df_for_quantiles_plos = preselection_df3.drop_duplicates(subset=['paper_UT'])   # ojo!!! dont use preselection_df3 directly because there are REPETITIONS!!!!\n",
    "\n",
    "    quantiles=sorted(list(df_for_quantiles_plos['paper_cite_count'].quantile(list_q_plos).to_dict().items())) #mean 10.68 \n",
    "\n",
    "    print (\"\\n\\ncitation bins for the selected plos:\", list_q_plos)#,quantiles, df_for_quantiles_plos.shape)   \n",
    "\n",
    "    lista_bins_plos=[]\n",
    "    old_value=0\n",
    "    for item in quantiles:\n",
    "        pair=[old_value, int(item[1])]\n",
    "        lista_bins_plos.append(pair)\n",
    "        old_value = int(item[1])\n",
    "\n",
    "    #print (lista_bins_plos, min(preselection_df3['paper_cite_count']), max(preselection_df3['paper_cite_count']))\n",
    "\n",
    "    print (\"\\nbins for PLOS papers:\")\n",
    "\n",
    "    cont = 0\n",
    "    dict_bin_list_plos_UT={}\n",
    "    for item in lista_bins_plos:\n",
    "\n",
    "        minimo = item[0]\n",
    "        maximo = item[1]   \n",
    "\n",
    "        df_select = preselection_df3[(preselection_df3['paper_cite_count'] >= minimo)  &  (preselection_df3['paper_cite_count'] < maximo)]\n",
    "        llave=str(minimo)+\"-\"+str(maximo)\n",
    "        dict_bin_list_plos_UT[llave]= list(df_select.paper_UT.unique())\n",
    "        print (\" \",llave, \"  N:\",len(list(df_select.reference_UT.unique())), \"  avg # ref:\",df_select.drop_duplicates(subset=['paper_UT']).total_refs.mean())\n",
    "        max_key_plos=llave\n",
    "\n",
    "\n",
    "        if cont ==0:\n",
    "            min_key_plos = llave\n",
    "            string_range_bottom_plos =   \"[\"+llave+\"] citations\"\n",
    "\n",
    "\n",
    "        cont  +=1\n",
    "\n",
    "\n",
    "\n",
    "        string_range_top_plos =  \"[\"+llave+\"] citations\"  \n",
    "\n",
    "    print (\"string for bottom:\", string_range_bottom_plos, \" string for top:\", string_range_top_plos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########## i define quantiles for references (based on their FINAL number of citations)\n",
    "    #list_q_ref=[.2,.8,1]\n",
    "    list_q_ref=[.1,.9,1]\n",
    "\n",
    "    #list_q_ref=[.05,.95,1]\n",
    "    df_for_quantiles_ref = preselection_df3.drop_duplicates(subset=['reference_UT'])   # ojo!!! remember to remove REPETITIONS!!!!\n",
    "    quantiles=sorted(list(df_for_quantiles_ref['cite_count'].quantile(list_q_ref).to_dict().items())) #mean 10.68 \n",
    "\n",
    "    print (\"\\n\\ncitation bins for the references in the selected plos:\", list_q_ref,quantiles)    \n",
    "\n",
    "    lista_bins=[]\n",
    "    old_value=0\n",
    "    for item in quantiles:\n",
    "        pair=[old_value, int(item[1])]\n",
    "        lista_bins.append(pair)\n",
    "        old_value = int(item[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\nbins for refrences:\")\n",
    "\n",
    "\n",
    "    cont = 0\n",
    "    dict_bin_list_ref_UT={}\n",
    "    for item in lista_bins:\n",
    "\n",
    "        minimo = item[0]\n",
    "        maximo = item[1]    \n",
    "\n",
    "        df_select = preselection_df3[(preselection_df3['cite_count'] >= minimo)  &  (preselection_df3['cite_count'] < maximo)]\n",
    "        llave=str(minimo)+\"-\"+str(maximo)\n",
    "        dict_bin_list_ref_UT[llave]=list(df_select.reference_UT.unique())\n",
    "        print (\" \",llave, \"N:\",len(list(df_select.reference_UT.unique())), \"  avg # ref:\",df_select.drop_duplicates(subset=['reference_UT']).total_refs.mean())\n",
    "        max_key_ref=llave\n",
    "\n",
    "        if cont ==0:\n",
    "            min_key_ref = llave\n",
    "        cont  +=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############### i create the list of top plos, top ref, bottom plos and bottom ref:\n",
    "    #########################\n",
    "\n",
    "    lista_top_plos = dict_bin_list_plos_UT[max_key_plos]\n",
    "    print (\"\\n\\n# UTs top\",(100-100*list_q_plos[-2]),\"% plos:\",len(lista_top_plos))\n",
    "\n",
    "    lista_top_ref=dict_bin_list_ref_UT[max_key_ref]\n",
    "    print (\"# UTs top\",(100-100*list_q_ref[-2]),\"% ref:\", len(lista_top_ref))\n",
    "\n",
    "\n",
    "    lista_bottom_plos = dict_bin_list_plos_UT[min_key_plos]\n",
    "    print (\"# UTs bottom \",(100*list_q_plos[0]),\"% plos:\",len(lista_bottom_plos))\n",
    "\n",
    "    lista_bottom_ref=dict_bin_list_ref_UT[min_key_ref]\n",
    "    print (\"# UTs bottom \",(100*list_q_ref[0]),\"% ref:\", len(lista_bottom_ref))\n",
    "\n",
    "    list_plos_in_year= list(preselection_df3.paper_UT.unique())\n",
    "    print (\"Tot # records:\",len(preselection_df3),\", # plos:\",len(list_plos_in_year))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######  i look at the usage of the top ref\n",
    "    ################################################  \n",
    "\n",
    "    df_top_ref = preselection_df3[preselection_df3['reference_UT'].isin(lista_top_ref)]\n",
    "\n",
    "\n",
    "    df_top_ref_top_plos = df_top_ref[df_top_ref['paper_UT'].isin(lista_top_plos)]\n",
    "    df_top_ref_bottom_plos = df_top_ref[df_top_ref['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "\n",
    "    usage_top_ref_top_plos = len(df_top_ref_top_plos)/float(len(df_top_ref))\n",
    "    usage_top_ref_bottom_plos = len(df_top_ref_bottom_plos)/float(len(df_top_ref))\n",
    "\n",
    "\n",
    "    print (\"fraction of usage of top ref by \")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\",  usage_top_ref_top_plos)\n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\",usage_top_ref_bottom_plos  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######  i look at the usage of the non-top ref\n",
    "    ################################################      \n",
    "\n",
    "    df_non_top_ref = preselection_df3[preselection_df3['reference_UT'].isin(lista_bottom_ref)]\n",
    "\n",
    "\n",
    "    df_non_top_ref_top_plos = df_non_top_ref[df_non_top_ref['paper_UT'].isin(lista_top_plos)]\n",
    "    df_non_top_ref_bottom_plos = df_non_top_ref[df_non_top_ref['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "    usage_non_top_ref_top_plos = len(df_non_top_ref_top_plos)/float(len(df_non_top_ref))\n",
    "    usage_non_top_ref_bottom_plos = len(df_non_top_ref_bottom_plos)/float(len(df_non_top_ref))\n",
    "\n",
    "\n",
    "    print (\"fraction of usage of non-top ref by \")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\", usage_non_top_ref_top_plos )\n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\", usage_non_top_ref_bottom_plos )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####################\n",
    "    # I canculate the null model (usage of references by top and non top plos papers, from the randomized data)\n",
    "    #################################################  \n",
    "\n",
    "    lista_usage_top_ref_by_top_plos_rand = []\n",
    "    lista_usage_top_ref_by_bottom_plos_rand = []\n",
    "\n",
    "    lista_usage_nontop_ref_by_top_plos_rand = []\n",
    "    lista_usage_nontop_ref_by_bottom_plos_rand = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### first i get the list of lists corresponding to the references used in the selected df, preserving the reference grouping or isolation:  \n",
    "    lista_lists_values = get_list_lists_references(preselection_df3)\n",
    "\n",
    "    print (\"len list_lists_all_ref:\",len(lista_lists_values), preselection_df3.shape)\n",
    "\n",
    "\n",
    "    for i in range(Niter):\n",
    "\n",
    "        print (i)\n",
    "\n",
    "\n",
    "\n",
    "        #### old, simple randomization scheme (only controling for year)\n",
    "    #     lista_values = list(preselection_df3.reference_UT)   #[i for i in range (len(df_merged))]\n",
    "    #     random.shuffle(lista_values)\n",
    "    #     preselection_df3['randomized_ref_UT'] = lista_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ########   new randomization scheme (controling for year, but also preserving groups of references cited together in a paper):   \n",
    "        #### lista_values is created outside the Niter loop   (i only need to do it once per selected df)    \n",
    "\n",
    "\n",
    "\n",
    "        random.shuffle(lista_lists_values)      \n",
    "        ### to flat out a list of lists:   \n",
    "        flat_list = []    \n",
    "        for sublist in lista_lists_values:\n",
    "            for item in sublist:\n",
    "                flat_list.append(item)\n",
    "\n",
    "\n",
    "       # print (\"len flat list:\", len(flat_list), preselection_df3.shape)\n",
    "\n",
    "        preselection_df3['randomized_ref_UT'] = flat_list   ### ojo!!! esto randomiza paper_UT, no reference_UT  !!!!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ####### (RANDOMIZED)  i look at the usage of the top ref\n",
    "        df_top_ref_rand = preselection_df3[preselection_df3['randomized_ref_UT'].isin(lista_top_ref)]\n",
    "\n",
    "        df_top_ref_top_plos_rand = df_top_ref_rand[df_top_ref_rand['paper_UT'].isin(lista_top_plos)]\n",
    "        df_top_ref_bottom_plos_rand = df_top_ref_rand[df_top_ref_rand['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "\n",
    "        usage_top_ref_top_plos_rand = len(df_top_ref_top_plos_rand)/float(len(df_top_ref_rand))\n",
    "        usage_top_ref_bottom_plos_rand = len(df_top_ref_bottom_plos_rand)/float(len(df_top_ref_rand))\n",
    "\n",
    "\n",
    "        lista_usage_top_ref_by_top_plos_rand.append(usage_top_ref_top_plos_rand)\n",
    "        lista_usage_top_ref_by_bottom_plos_rand.append(usage_top_ref_bottom_plos_rand)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #######  (RANDOMIZED) i look at the usage of the non-top ref            \n",
    "        df_non_top_ref_rand = preselection_df3[preselection_df3['randomized_ref_UT'].isin(lista_bottom_ref)]        \n",
    "\n",
    "        df_non_top_ref_top_plos_rand = df_non_top_ref_rand[df_non_top_ref_rand['paper_UT'].isin(lista_top_plos)]\n",
    "        df_non_top_ref_bottom_plos_rand = df_non_top_ref_rand[df_non_top_ref_rand['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "\n",
    "        usage_non_top_ref_top_plos_rand = len(df_non_top_ref_top_plos_rand)/float(len(df_non_top_ref_rand))\n",
    "        usage_non_top_ref_bottom_plos_rand = len(df_non_top_ref_bottom_plos_rand)/float(len(df_non_top_ref_rand))\n",
    "\n",
    "\n",
    "        lista_usage_nontop_ref_by_top_plos_rand.append(usage_non_top_ref_top_plos_rand)\n",
    "        lista_usage_nontop_ref_by_bottom_plos_rand.append(usage_non_top_ref_bottom_plos_rand)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"plos category:\", string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\n\\n\\n\\navg randomized!!\")\n",
    "    print(\"fraction of usage of top ref by\")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\",  np.mean(lista_usage_top_ref_by_top_plos_rand) )   \n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\",np.mean(lista_usage_top_ref_by_bottom_plos_rand)  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\n\\navg randomized\")\n",
    "    print (\"fraction of usage of non-top ref by \")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\", np.mean(lista_usage_nontop_ref_by_top_plos_rand) )   \n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\", np.mean(lista_usage_nontop_ref_by_bottom_plos_rand) ,\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #############################  second part\n",
    "\n",
    "\n",
    "    ###  PLOT FIGURE FOR MORE SOPHISTICATED VERSION OF THE RANDOMIZATION SCHEME\n",
    "    ######     (RUN PREVIOUS CELL FIRST, TO GET THE BOOT-STRAPPING DATA)\n",
    "\n",
    "\n",
    "    ### group by Top PApers  Bottom Papers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    #lista_bin_names=['Top '+str(int(100-100*list_q_plos[-2]))+'%<br>papers', 'Bottom '+str(int(list_q_plos[0]*100))+'%<br>papers']\n",
    "    #lista_bin_names = ['Bottom '+str(int(list_q_plos[0]*100))+'%<br>papers', 'Top '+str(int(100-100*list_q_plos[-2]))+'%<br>papers']\n",
    "\n",
    "    lista_bin_names = ['Bottom '+str(int(list_q_plos[0]*100))+'% papers<br>'+string_range_bottom_plos, 'Top '+str(int(100-100*list_q_plos[-2]))+'% papers<br>'+string_range_top_plos]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lista_for_top_ref = [ usage_top_ref_top_plos, usage_top_ref_bottom_plos]\n",
    "    lista_for_bottom_ref = [usage_non_top_ref_top_plos, usage_non_top_ref_bottom_plos]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lista_for_top_ref = [  usage_top_ref_bottom_plos, usage_top_ref_top_plos]\n",
    "    lista_for_bottom_ref = [usage_non_top_ref_bottom_plos, usage_non_top_ref_top_plos]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###### this is the null model \n",
    "\n",
    "\n",
    "    # lista_expectations_top_ref = [np.mean(lista_usage_top_ref_by_top_plos_rand),np.mean(lista_usage_top_ref_by_bottom_plos_rand)]  \n",
    "    # lista_expectations_bottom_ref = [np.mean(lista_usage_nontop_ref_by_top_plos_rand), np.mean(lista_usage_nontop_ref_by_bottom_plos_rand)] \n",
    "\n",
    "\n",
    "    lista_expectations_top_ref = [np.mean(lista_usage_top_ref_by_bottom_plos_rand), np.mean(lista_usage_top_ref_by_top_plos_rand)]  \n",
    "    lista_expectations_bottom_ref = [ np.mean(lista_usage_nontop_ref_by_bottom_plos_rand),np.mean(lista_usage_nontop_ref_by_top_plos_rand)] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # list_errors_top_ref = [2.*np.std(lista_usage_top_ref_by_top_plos_rand), 2.*np.std(lista_usage_top_ref_by_bottom_plos_rand)] \n",
    "    # list_errors_bottom_ref = [2.*np.std(lista_usage_nontop_ref_by_top_plos_rand) , 2.*np.std(lista_usage_nontop_ref_by_bottom_plos_rand)] \n",
    "\n",
    "\n",
    "    list_errors_top_ref = [2.*np.std(lista_usage_top_ref_by_bottom_plos_rand), 2.*np.std(lista_usage_top_ref_by_top_plos_rand) ] \n",
    "    list_errors_bottom_ref = [2.*np.std(lista_usage_nontop_ref_by_bottom_plos_rand), 2.*np.std(lista_usage_nontop_ref_by_top_plos_rand) ] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    z_score_top_ref_by_top_plos = (usage_top_ref_top_plos - np.mean(lista_usage_top_ref_by_top_plos_rand))/np.std(lista_usage_top_ref_by_top_plos_rand)\n",
    "    z_score_nontop_ref_by_top_plos = (usage_non_top_ref_top_plos - np.mean(lista_usage_nontop_ref_by_top_plos_rand))/np.std(lista_usage_nontop_ref_by_top_plos_rand)\n",
    "\n",
    "    z_score_top_ref_by_bottom_plos = (usage_top_ref_bottom_plos - np.mean(lista_usage_top_ref_by_bottom_plos_rand))/np.std(lista_usage_top_ref_by_bottom_plos_rand)\n",
    "    z_score_nontop_ref_by_bottom_plos = (usage_non_top_ref_bottom_plos - np.mean(lista_usage_nontop_ref_by_bottom_plos_rand))/np.std(lista_usage_nontop_ref_by_bottom_plos_rand)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print ('zscore top ref cited  by top plos:', z_score_top_ref_by_top_plos)\n",
    "    print ('zscore bottom ref cited  by top plos:', z_score_nontop_ref_by_top_plos)\n",
    "\n",
    "    print ('zscore top ref cited  by bottom plos:', z_score_top_ref_by_bottom_plos)\n",
    "    print ('zscore bottom ref cited  by bottom plos:', z_score_nontop_ref_by_bottom_plos)\n",
    "\n",
    "\n",
    "\n",
    "    title_string=''#'s top-ref by top plos: '+str(z_score_top_ref_by_top_plos)+';  zs top-ref by bottom plos: '+str(z_score_top_ref_by_bottom_plos)+\\\n",
    "    #'<br>zs nontop-ref by top plos: '+str(z_score_nontop_ref_by_top_plos)+';  zs nontop-ref by bottom plos: '+str(z_score_nontop_ref_by_bottom_plos)\n",
    "\n",
    "\n",
    "\n",
    "    size_bar_name = 30#45\n",
    "    y_pos_bar_names = -.039\n",
    "    angle = -70\n",
    "\n",
    "    trace1 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_for_top_ref,\n",
    "    #     text=['by top '+str(int(100-100*list_q_plos[-2]))+'% papers', 'by top '+str(int(100-100*list_q_plos[-2]))+'% papers'],    \n",
    "    #     name='by top '+str(int(100-100*list_q_plos[-2]))+'% papers',   \n",
    "        marker=dict(\n",
    "            color='#88419d',           \n",
    "        ),\n",
    "\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    trace2 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_expectations_top_ref,\n",
    "    #     name='   expected value',\n",
    "    #     text=['Expected value for top', 'Expected value for top'],  \n",
    "        error_y=dict(\n",
    "           # type='data',\n",
    "            array=list_errors_top_ref,\n",
    "            thickness=5,\n",
    "            visible=True\n",
    "        ),\n",
    "        marker=dict(\n",
    "            color='#c994c7',         \n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "    trace3 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_for_bottom_ref,\n",
    "    #     name='by bottom '+str(int(list_q_plos[0]*100))+'% papers', \n",
    "    #     text=['by bottom '+str(int(list_q_plos[0]*100))+'% papers','by bottom '+str(int(list_q_plos[0]*100))+'% papers'],\n",
    "        marker=dict(\n",
    "            color='#225ea8',   \n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "    trace4 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_expectations_bottom_ref,\n",
    "      #  name='   expected value',\n",
    "\n",
    "        error_y=dict(       \n",
    "            array=list_errors_bottom_ref,#[0.5, 1, 2],\n",
    "            thickness=5,\n",
    "            visible=True\n",
    "        ),\n",
    "        marker=dict(\n",
    "            color='#a6bddb',     \n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data = [trace1, trace2, trace3, trace4]\n",
    "    layout = go.Layout(   \n",
    "        title=title_string,\n",
    "        xaxis = dict(\n",
    "            side= 'top',\n",
    "            range = [-.5,1.5],\n",
    "           # showline =  True,\n",
    "            #title= 'Plos Citation percentile'),\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title= 'Fraction references cited',\n",
    "            range = [-.07,0.17],\n",
    "            tickvals=[0.0,0.05,0.1,0.15],\n",
    "            #showline =  True,\n",
    "             ),\n",
    "\n",
    "        showlegend=False,\n",
    "    #     legend=dict(x=0.75, y=1.05,                 \n",
    "    #                font=dict(\n",
    "    #                     #family='sans-serif',\n",
    "    #                     size=40,\n",
    "    #                     #color='#000'\n",
    "    #                     ),\n",
    "    #                 ),\n",
    "\n",
    "\n",
    "    #     barmode='stacked',#group',\n",
    "       # bargap=0.2,\n",
    "        bargroupgap=0.15,\n",
    "\n",
    "        annotations = [  \n",
    "            # the four bars on the left\n",
    "            dict(\n",
    "              x = -.34,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Top '+str(int(100-100*list_q_ref[-2]))+'%<br>references',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),    \n",
    "            dict(\n",
    "              x = -0.14,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Null Model',\n",
    "               textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = .08,\n",
    "              y = y_pos_bar_names,\n",
    "              showarrow = False,\n",
    "              text = 'Bottom '+str(int(list_q_ref[0]*100))+'%<br>references', \n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = .28,\n",
    "              y = y_pos_bar_names,\n",
    "              text =  'Null Model',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "\n",
    "\n",
    "\n",
    "            # the four bars on the right\n",
    "            dict(  \n",
    "              x = .68,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Top '+str(int(100-100*list_q_ref[-2]))+'%<br>references',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = .88,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Null Model',\n",
    "               textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = 1.08,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Bottom '+str(int(list_q_ref[0]*100))+'%<br>references', \n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = 1.28,\n",
    "              y = y_pos_bar_names,\n",
    "              text =  'Null Model',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "\n",
    "\n",
    "            ],    \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    font_gral=55  # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "    fig['layout']['font']['size'] = font_gral-5\n",
    "\n",
    "\n",
    "    # Altering x axis\n",
    "    #fig['layout']['xaxis']['tickfont']['family'] = 'Gill Sans MT'\n",
    "    fig['layout']['xaxis']['tickangle'] = 0\n",
    "    # fig['layout']['yaxis']['tickangle'] = -90\n",
    "    # fig['layout']['xaxis']['titlefont']['size'] = font_gral -10\n",
    "    # fig['layout']['yaxis']['titlefont']['size'] = font_gral -10\n",
    "\n",
    "    fig['layout']['xaxis']['tickfont']['size'] = font_gral -5\n",
    "    fig['layout']['yaxis']['tickfont']['size'] = font_gral -10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig['layout']['margin']=dict(\n",
    "            l=300,\n",
    "           # r=50,\n",
    "            b=100,\n",
    "            t=200,\n",
    "            pad=15\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    py.iplot(fig, filename='grouped-bar')\n",
    "\n",
    "\n",
    "    fig_filename='fract_usage_top_bottom_ref_'+str(years[0])+string_code_categ.replace(\" \",\"_\")\n",
    "    offline.plot(fig, auto_open=True, image = 'png', image_filename='../plots/'+fig_filename ,image_width=2000, image_height=1200, filename='../plots/'+fig_filename+'.html', validate=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # earth science, 2013, 1000 iter, simple randomization scheme:\n",
    "\n",
    "    # zscore top ref cited  by top plos: 1.8633822051\n",
    "    # zscore bottom ref cited  by top plos: -8.29803601221\n",
    "    # zscore top ref cited  by bottom plos: -4.18320566755\n",
    "    # zscore bottom ref cited  by bottom plos: 2.22458205576\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## earth science, 2013, 1000 iter, more sophisticated randomization scheme (preserving reference groups/isolated references):\n",
    "\n",
    "    # zscore top ref cited  by top plos: 1.61069883113\n",
    "    # zscore bottom ref cited  by top plos: -8.02168733553\n",
    "    # zscore top ref cited  by bottom plos: -3.84738913187\n",
    "    # zscore bottom ref cited  by bottom plos: 2.16556097748\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
