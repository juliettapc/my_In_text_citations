{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#Due to leftoevererrors in Nathan's python installation, some cleaning up occurs here\n",
    "#sys.path.append(\"./code/\")\n",
    "#sys.path.remove('/usr/local/lib/python2.7/site-packages') \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import datetime\n",
    "import pickle\n",
    "import gzip\n",
    "import os,glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import random\n",
    "from  scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "import itertools\n",
    "#sys.path\n",
    "\n",
    "\n",
    "import regex as re\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='juliettapc', api_key='nM6iUdx6dGaOiPXQTwpP')   # go to: https://plot.ly/settings/api#/   for a new key if needed\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 s, sys: 1.02 s, total: 5.1 s\n",
      "Wall time: 10 s\n",
      "done loading pickles (5787634, 34)\n",
      "(156558, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence</th>\n",
       "      <th>reference_UT</th>\n",
       "      <th>reference_rank</th>\n",
       "      <th>regex_sect_index</th>\n",
       "      <th>cite_count</th>\n",
       "      <th>ref_pub_year</th>\n",
       "      <th>paper_cite_count</th>\n",
       "      <th>plos_pub_year</th>\n",
       "      <th>sect_char_pos</th>\n",
       "      <th>sect_char_total</th>\n",
       "      <th>...</th>\n",
       "      <th>plos_article_type</th>\n",
       "      <th>num_cit_young_ref_by2009</th>\n",
       "      <th>num_cit_young_ref_by2010</th>\n",
       "      <th>num_cit_young_ref_by2011</th>\n",
       "      <th>num_cit_young_ref_by2012</th>\n",
       "      <th>num_cit_young_ref_by2013</th>\n",
       "      <th>num_cit_young_ref_by2009after8</th>\n",
       "      <th>num_cit_young_ref_by2008after8</th>\n",
       "      <th>num_cit_young_ref_by2010after8</th>\n",
       "      <th>num_cit_young_ref_by2007after8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>494</td>\n",
       "      <td>5398</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>000263911400006</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>142</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>000289279600018</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>269</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>000289279600018</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3844</td>\n",
       "      <td>5398</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   occurence     reference_UT  reference_rank  regex_sect_index  cite_count  \\\n",
       "0          1  A1995QY75100004               1                 0        60.0   \n",
       "1          2  A1995QY75100004               1                 3        60.0   \n",
       "4          1  000263911400006               3                 0         5.0   \n",
       "5          1  000289279600018               4                 0        29.0   \n",
       "6          3  000289279600018               4                 3        29.0   \n",
       "\n",
       "   ref_pub_year  paper_cite_count  plos_pub_year  sect_char_pos  \\\n",
       "0        1995.0                 2         2013.0            139   \n",
       "1        1995.0                 2         2013.0            494   \n",
       "4        2009.0                 2         2013.0            142   \n",
       "5        2011.0                 2         2013.0            269   \n",
       "6        2011.0                 2         2013.0           3844   \n",
       "\n",
       "   sect_char_total              ...               plos_article_type  \\\n",
       "0             4029              ...                       @ Article   \n",
       "1             5398              ...                       @ Article   \n",
       "4             4029              ...                       @ Article   \n",
       "5             4029              ...                       @ Article   \n",
       "6             5398              ...                       @ Article   \n",
       "\n",
       "  num_cit_young_ref_by2009 num_cit_young_ref_by2010  num_cit_young_ref_by2011  \\\n",
       "0                      NaN                      NaN                       NaN   \n",
       "1                      NaN                      NaN                       NaN   \n",
       "4                      0.0                      0.0                       NaN   \n",
       "5                      0.0                      0.0                       0.0   \n",
       "6                      0.0                      0.0                       0.0   \n",
       "\n",
       "   num_cit_young_ref_by2012  num_cit_young_ref_by2013  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "5                       3.0                       NaN   \n",
       "6                       3.0                       NaN   \n",
       "\n",
       "   num_cit_young_ref_by2009after8 num_cit_young_ref_by2008after8  \\\n",
       "0                             NaN                            NaN   \n",
       "1                             NaN                            NaN   \n",
       "4                             5.0                            5.0   \n",
       "5                            39.0                           39.0   \n",
       "6                            39.0                           39.0   \n",
       "\n",
       "   num_cit_young_ref_by2010after8 num_cit_young_ref_by2007after8  \n",
       "0                             NaN                            NaN  \n",
       "1                             NaN                            NaN  \n",
       "4                             5.0                            5.0  \n",
       "5                            39.0                           39.0  \n",
       "6                            39.0                           39.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                  \n",
    "\n",
    "####  NEW FILE INCLUDING EARLY CITATIONS OF YOUNG REFERENCES:   ../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit.pkl\n",
    "                                            \n",
    "#%time df_merged = pickle.load(open('../data/df_reference_cite_plos_merged_simplified_added_more_columns_no_self-cit_one_ref_per_sect_ONLY_ARTICLES.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "%time df_merged = pickle.load(open('../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit_and_after_accretion_time.pkl', 'rb'))\n",
    "print (\"done loading pickles\", df_merged.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_merged = df_merged[df_merged['cite_count'] != -1]   # i dont know why, but there are 7 occurrences with value -1\n",
    "\n",
    "\n",
    "\n",
    "plos_df = df_merged.drop_duplicates(subset=['paper_UT'])\n",
    "print (plos_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from the entire df  (5787630, 34)   ; and plos one records: (5368040, 34) \n",
      "\n",
      "\n",
      "5087018 Biology and life sciences\n",
      "3807428 Medicine and health sciences\n",
      "3260169 Research and analysis methods\n",
      "1766356 Physical sciences\n",
      "1035007 Computer and information sciences\n",
      "647228 Social sciences\n",
      "579580 People and places\n",
      "526791 Ecology and environmental sciences\n",
      "444753 Earth sciences\n",
      "322656 Engineering and technology\n",
      "36492 Science policy\n"
     ]
    }
   ],
   "source": [
    "#### dictionary category-code\n",
    "#   ../data/dict_categ_code.pkl\n",
    "\n",
    "\n",
    "\n",
    "dict_categ_code = pickle.load(open('../data/dict_categ_code.pkl', 'rb'))\n",
    "#print (len(dict_categ_code))\n",
    "\n",
    "\n",
    "\n",
    "print (\"from the entire df \",df_merged.shape, \"  ; and plos one records:\",  df_merged[df_merged['plos_j1']== \"PLOS ONE\"].shape,\"\\n\\n\")\n",
    "# {'Biology and life sciences': 0,\n",
    "#  'Computer and information sciences': 1,\n",
    "#  'Earth sciences': 2,\n",
    "#  'Ecology and environmental sciences': 3,\n",
    "#  'Engineering and technology': 4,\n",
    "#  'Medicine and health sciences': 5,\n",
    "#  'People and places': 6,\n",
    "#  'Physical sciences': 7,\n",
    "#  'Research and analysis methods': 8,\n",
    "#  'Science policy': 9,\n",
    "#  'Social sciences': 10}\n",
    "\n",
    "dict_code_categ={}\n",
    "dict_size_categ={}\n",
    "for categ in dict_categ_code:\n",
    "    code = str(dict_categ_code[categ])\n",
    "    \n",
    "    df_selection_categ = df_merged[df_merged['categ_codes'].str.contains(code)]\n",
    "   # print (categ, code, df_selection_categ.shape)\n",
    "    size= len(df_selection_categ)\n",
    "    dict_size_categ[size] = categ\n",
    "    dict_code_categ[code] = categ\n",
    "\n",
    "for size in reversed(sorted(dict_size_categ)):\n",
    "    print (size, dict_size_categ[size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 442 ms, sys: 88.4 ms, total: 530 ms\n",
      "Wall time: 529 ms\n",
      "done loading plos_df (156610, 87)\n",
      "df_merged (5787630, 58)\n",
      "(156558, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence</th>\n",
       "      <th>reference_UT</th>\n",
       "      <th>reference_rank</th>\n",
       "      <th>regex_sect_index</th>\n",
       "      <th>cite_count</th>\n",
       "      <th>ref_pub_year</th>\n",
       "      <th>paper_cite_count</th>\n",
       "      <th>plos_pub_year</th>\n",
       "      <th>sect_char_pos</th>\n",
       "      <th>sect_char_total</th>\n",
       "      <th>...</th>\n",
       "      <th>fract_old_ref_section6</th>\n",
       "      <th>fract_old_ref_section7</th>\n",
       "      <th>fract_young_ref_section0</th>\n",
       "      <th>fract_young_ref_section1</th>\n",
       "      <th>fract_young_ref_section2</th>\n",
       "      <th>fract_young_ref_section3</th>\n",
       "      <th>fract_young_ref_section4</th>\n",
       "      <th>fract_young_ref_section5</th>\n",
       "      <th>fract_young_ref_section6</th>\n",
       "      <th>fract_young_ref_section7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>000088374400026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>543</td>\n",
       "      <td>2207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>000313346100007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>591</td>\n",
       "      <td>2474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>000301376000017</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>762</td>\n",
       "      <td>2700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>000232311300030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>77</td>\n",
       "      <td>3195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     occurence     reference_UT  reference_rank  regex_sect_index  cite_count  \\\n",
       "0            1  A1995QY75100004               1                 0        60.0   \n",
       "31           1  000088374400026               1                 0       477.0   \n",
       "74           1  000313346100007               2                 0         6.0   \n",
       "85           1  000301376000017               2                 0        35.0   \n",
       "108          1  000232311300030               1                 0      1687.0   \n",
       "\n",
       "     ref_pub_year  paper_cite_count  plos_pub_year  sect_char_pos  \\\n",
       "0          1995.0                 2         2013.0            139   \n",
       "31         2000.0                 2         2015.0            543   \n",
       "74         2013.0                 1         2015.0            591   \n",
       "85         2012.0                 8         2012.0            762   \n",
       "108        2005.0                98         2008.0             77   \n",
       "\n",
       "     sect_char_total           ...            fract_old_ref_section6  \\\n",
       "0               4029           ...                               0.0   \n",
       "31              2207           ...                               0.0   \n",
       "74              2474           ...                               0.0   \n",
       "85              2700           ...                               0.0   \n",
       "108             3195           ...                               0.0   \n",
       "\n",
       "    fract_old_ref_section7 fract_young_ref_section0  fract_young_ref_section1  \\\n",
       "0                      0.0                 0.000000                       0.0   \n",
       "31                     0.0                 0.023256                       0.0   \n",
       "74                     0.0                 0.181818                       0.0   \n",
       "85                     0.0                 0.130435                       0.0   \n",
       "108                    0.0                 0.000000                       0.0   \n",
       "\n",
       "     fract_young_ref_section2  fract_young_ref_section3  \\\n",
       "0                         0.0                  0.032258   \n",
       "31                        0.0                  0.023256   \n",
       "74                        0.0                  0.090909   \n",
       "85                        0.0                  0.086957   \n",
       "108                       0.0                  0.040000   \n",
       "\n",
       "     fract_young_ref_section4 fract_young_ref_section5  \\\n",
       "0                         0.0                      0.0   \n",
       "31                        0.0                      0.0   \n",
       "74                        0.0                      0.0   \n",
       "85                        0.0                      0.0   \n",
       "108                       0.0                      0.0   \n",
       "\n",
       "     fract_young_ref_section6 fract_young_ref_section7  \n",
       "0                         0.0                      0.0  \n",
       "31                        0.0                      0.0  \n",
       "74                        0.0                      0.0  \n",
       "85                        0.0                      0.0  \n",
       "108                       0.0                      0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ######  i create the new columns for fraction of references in each section (labelled 0 to 7)\n",
    "\n",
    "\n",
    "\n",
    "# %time plos_df = pickle.load(open('../data/plos_paper_dataframe_ONLY_ARTICLES_num_ref_sect_young_old.pkl', 'rb'))\n",
    "# print (\"done loading plos_df\", plos_df.shape)\n",
    "# plos_df_simplified = plos_df[['paper_UT','num_ref_section0','num_ref_section1','num_ref_section2','num_ref_section3','num_ref_section4','num_ref_section5','num_ref_section6','num_ref_section7',\n",
    "#     'fract_old_ref_section0', 'fract_old_ref_section1', 'fract_old_ref_section2', 'fract_old_ref_section3', 'fract_old_ref_section4', 'fract_old_ref_section5', 'fract_old_ref_section6', 'fract_old_ref_section7',\\\n",
    "#     'fract_young_ref_section0', 'fract_young_ref_section1', 'fract_young_ref_section2', 'fract_young_ref_section3', 'fract_young_ref_section4', 'fract_young_ref_section5', 'fract_young_ref_section6', 'fract_young_ref_section7']]\n",
    "\n",
    "# # print (\"plos_df_simplified\", plos_df_simplified.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #df_merged = pd.merge(df_merged, plos_df_simplified, on='paper_UT', how='left')\n",
    "# df_merged = pd.merge(df_merged, plos_df_simplified, on='paper_UT', how='left')\n",
    "# print (\"df_merged\", df_merged.shape)\n",
    "\n",
    "# # df_merged[['paper_UT','reference_UT','regex_sect_index','eff_num_ref','num_ref_section0','num_ref_section1','num_ref_section2','num_ref_section3','num_ref_section4','num_ref_section5','num_ref_section6','num_ref_section7']].head(100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_records_one_ref_per_plos = df_merged.drop_duplicates(subset=['paper_UT'])\n",
    "# print (df_records_one_ref_per_plos.shape)\n",
    "\n",
    "\n",
    "\n",
    "# # df_records_one_ref_per_plos.rename(columns={'paper_cite_count_x': 'paper_cite_count', 'plos_pub_year_x': 'plos_pub_year', 'ref_pub_year_x':'ref_pub_year','regex_sect_index_x':'regex_sect_index', 'total_refs_x':'total_refs'}, inplace=True)\n",
    "# # df_merged.rename(columns={'paper_cite_count_x': 'paper_cite_count', 'plos_pub_year_x': 'plos_pub_year', 'ref_pub_year_x':'ref_pub_year','regex_sect_index_x':'regex_sect_index', 'total_refs_x':'total_refs','reference_UT_x':'reference_UT','cite_count_x':'cite_count'}, inplace=True)\n",
    "\n",
    "\n",
    "# sorted(df_records_one_ref_per_plos.columns)\n",
    "\n",
    "# df_records_one_ref_per_plos.head()\n",
    "\n",
    "\n",
    "\n",
    "# ###OJO!!!!! FALTA POR HACER BIEN EL MERGE PARA EVITAR REPETICION DE COLUMNAS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### i need this function to do the randomization scheme that preserves groups of references cited together in  a paper\n",
    "\n",
    "def get_list_lists_references(preselection_df3):\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ####  NOTA: preselection_df3 only includes one instance of paper_UT-ref_UT  (the first occurrence in each paper), and i sort it too:\n",
    "    preselection_df3.sort_values(by=['paper_UT','reference_UT'], inplace=True)\n",
    "\n",
    "\n",
    "    distance_threshold = 5  # characters tops to separate group ref\n",
    "\n",
    "    list_lists_all_ref = []  # WITH STRUCTURE\n",
    "    lista_ref = []           # WITHOUT STRUCTURE\n",
    "    cont = 0\n",
    "    for paper_UT, group_df in preselection_df3.groupby(['paper_UT']):  #### OJO!!!! THIS LOOP IS WAY FASTER THAN DOING:  for   paper_UT in list_paper_UT    !!!!    \n",
    "\n",
    "        group_df.sort_values(by=['regex_sect_index','sect_char_pos','reference_UT'],inplace = True)  # i sort the reference of a paper by section first, then by location within the section\n",
    "\n",
    "\n",
    "\n",
    "        ### first i take care of the isolated references: \n",
    "        group_df1= group_df[group_df['isolated_citation'] ==1]        \n",
    "        for index, row in group_df1.iterrows():  \n",
    "\n",
    "            ref_UT = row['reference_UT']\n",
    "            aux = [ref_UT]\n",
    "            lista_ref.append(ref_UT)   \n",
    "            list_lists_all_ref.append(aux)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #### then i take care of the group references:\n",
    "        group_df0= group_df[group_df['isolated_citation'] == 0]  \n",
    "        previous_position = 0\n",
    "        list_group_ref = []\n",
    "        for index, row in group_df0.iterrows():\n",
    "\n",
    "            ref_UT = row['reference_UT']\n",
    "            lista_ref.append(ref_UT)   # list without structure (for comparison reasons)\n",
    "\n",
    "            position = row['sect_char_pos']\n",
    "\n",
    "            if previous_position == 0:  # for the very first entry                \n",
    "                list_group_ref.append(ref_UT)\n",
    "\n",
    "\n",
    "            else:  # for all other entries\n",
    "                if (position - previous_position) <= distance_threshold  :   # if the current ref is close to the previous one\n",
    "                     list_group_ref.append(ref_UT)\n",
    "                else: \n",
    "                    list_lists_all_ref.append(list_group_ref)\n",
    "                    list_group_ref = []\n",
    "                    list_group_ref.append(ref_UT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            previous_position = position\n",
    "\n",
    "        list_lists_all_ref.append(list_group_ref)  # i need this for the final group/isolated one!!!\n",
    "\n",
    "        cont +=1   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### i flatten out the list of lists for comparison purposes\n",
    "\n",
    "    flat_list = []    \n",
    "    for sublist in list_lists_all_ref:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "\n",
    "    print (\"list_lists created:\", len(list_lists_all_ref), ' without structure:', len(lista_ref), \"   flat_list:\", len(flat_list))\n",
    "\n",
    "\n",
    "    # for i in range(len(flat_list)):\n",
    "    #     print (lista_ref[i], flat_list[i])\n",
    "    \n",
    "\n",
    "    return list_lists_all_ref\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size: (5787630, 34)\n",
      "[2008]\n",
      "size of preselection1 (by plos years): (104056, 34)\n",
      "size of preselection1 (by isolated/group ref): (104056, 34) \n",
      " size of preselection (by plos ONE subject category): (95977, 34)  Biology and life sciences\n",
      " size of preselection2 (by plos journal): (95977, 34) \n",
      " size of preselection2 (by plos field): (95977, 34) \n",
      "     N plos: 2687   N  ref: 69604  N records: 95977\n",
      "OJO!!! EACH REFERENCE ONLY COUNTED ONCE PER PAPER:\n",
      "     N plos: 2687   N  ref: 69604  N records: 79000\n",
      "\n",
      "\n",
      "citation bins for the selected plos: [0.1, 0.9, 1]\n",
      "\n",
      "bins for PLOS papers:\n",
      "  0-7   N: 6060   avg # ref: 38.58\n",
      "  7-76   N: 57481   avg # ref: 45.280369515\n",
      "  76-787   N: 8569   avg # ref: 60.3948339483\n",
      "string for bottom: [0-7] citations  string for top: [76-787] citations\n",
      "\n",
      "\n",
      "citation bins for the references in the selected plos: [0.1, 0.9, 1] [(0.1, 22.0), (0.9, 549.0), (1.0, 326393.0)]\n",
      "\n",
      "bins for refrences:\n",
      "  0-22 N: 6664   avg # ref: 53.6332533013\n",
      "  22-549 N: 55966   avg # ref: 54.1429439302\n",
      "  549-326393 N: 6973   avg # ref: 54.1751039725\n",
      "\n",
      "\n",
      "# UTs top 10.0 % plos: 271\n",
      "# UTs top 10.0 % ref: 6973\n",
      "# UTs bottom  10.0 % plos: 250\n",
      "# UTs bottom  10.0 % ref: 6664\n",
      "Tot # records: 79000 , # plos: 2687\n",
      "fraction of usage of top ref by \n",
      "  top 10.0 % plos: 0.154388320187951\n",
      "  bottom 10.0 % plos: 0.06981037086759523\n",
      "fraction of usage of non-top ref by \n",
      "  top 10.0 % plos: 0.07648809523809524\n",
      "  bottom 10.0 % plos: 0.10416666666666667\n",
      "list_lists created: 59282  without structure: 79000    flat_list: 79000\n",
      "len list_lists_all_ref: 59282 (79000, 34)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "plos category:  Biology and life sciences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "avg randomized!!\n",
      "fraction of usage of top ref by\n",
      "  top 10.0 % plos: 0.114447893942\n",
      "  bottom 10.0 % plos: 0.078636516194\n",
      "\n",
      "\n",
      "avg randomized\n",
      "fraction of usage of non-top ref by \n",
      "  top 10.0 % plos: 0.115160714286\n",
      "  bottom 10.0 % plos: 0.0784330357143 \n",
      "\n",
      "\n",
      "\n",
      "zscore top ref cited  by top plos: 13.9294419905\n",
      "zscore bottom ref cited  by top plos: -11.6644232793\n",
      "zscore top ref cited  by bottom plos: -3.88566856057\n",
      "zscore bottom ref cited  by bottom plos: 8.37607662655\n",
      "original size: (5787630, 34)\n",
      "[2009]\n",
      "size of preselection1 (by plos years): (171018, 34)\n",
      "size of preselection1 (by isolated/group ref): (171018, 34) \n",
      " size of preselection (by plos ONE subject category): (160543, 34)  Biology and life sciences\n",
      " size of preselection2 (by plos journal): (160543, 34) \n",
      " size of preselection2 (by plos field): (160543, 34) \n",
      "     N plos: 4338   N  ref: 114269  N records: 160543\n",
      "OJO!!! EACH REFERENCE ONLY COUNTED ONCE PER PAPER:\n",
      "     N plos: 4338   N  ref: 114269  N records: 133149\n",
      "\n",
      "\n",
      "citation bins for the selected plos: [0.1, 0.9, 1]\n",
      "\n",
      "bins for PLOS papers:\n",
      "  0-6   N: 10095   avg # ref: 39.2780612245\n",
      "  6-62   N: 94987   avg # ref: 46.2429022082\n",
      "  62-421   N: 14080   avg # ref: 49.8406113537\n",
      "string for bottom: [0-6] citations  string for top: [62-421] citations\n",
      "\n",
      "\n",
      "citation bins for the references in the selected plos: [0.1, 0.9, 1] [(0.1, 20.0), (0.9, 486.0), (1.0, 326393.0)]\n",
      "\n",
      "bins for refrences:\n",
      "  0-20 N: 10627   avg # ref: 54.4327655971\n",
      "  20-486 N: 92181   avg # ref: 54.6185114069\n",
      "  486-326393 N: 11460   avg # ref: 52.7073298429\n",
      "\n",
      "\n",
      "# UTs top 10.0 % plos: 458\n",
      "# UTs top 10.0 % ref: 11460\n",
      "# UTs bottom  10.0 % plos: 392\n",
      "# UTs bottom  10.0 % ref: 10627\n",
      "Tot # records: 133149 , # plos: 4338\n",
      "fraction of usage of top ref by \n",
      "  top 10.0 % plos: 0.1453225198038476\n",
      "  bottom 10.0 % plos: 0.06931346661637118\n",
      "fraction of usage of non-top ref by \n",
      "  top 10.0 % plos: 0.0723531055033057\n",
      "  bottom 10.0 % plos: 0.10503771300866002\n",
      "list_lists created: 97647  without structure: 133149    flat_list: 133149\n",
      "len list_lists_all_ref: 97647 (133149, 34)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "plos category:  Biology and life sciences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "avg randomized!!\n",
      "fraction of usage of top ref by\n",
      "  top 10.0 % plos: 0.112332610336\n",
      "  bottom 10.0 % plos: 0.0774646359864\n",
      "\n",
      "\n",
      "avg randomized\n",
      "fraction of usage of non-top ref by \n",
      "  top 10.0 % plos: 0.112902504889\n",
      "  bottom 10.0 % plos: 0.0770155507962 \n",
      "\n",
      "\n",
      "\n",
      "zscore top ref cited  by top plos: 16.2050367836\n",
      "zscore bottom ref cited  by top plos: -14.2188157013\n",
      "zscore top ref cited  by bottom plos: -3.94014143746\n",
      "zscore bottom ref cited  by bottom plos: 13.0510787038\n",
      "original size: (5787630, 34)\n",
      "[2010]\n",
      "size of preselection1 (by plos years): (269213, 34)\n",
      "size of preselection1 (by isolated/group ref): (269213, 34) \n",
      " size of preselection (by plos ONE subject category): (256358, 34)  Biology and life sciences\n",
      " size of preselection2 (by plos journal): (256358, 34) \n",
      " size of preselection2 (by plos field): (256358, 34) \n",
      "     N plos: 6617   N  ref: 177852  N records: 256358\n",
      "OJO!!! EACH REFERENCE ONLY COUNTED ONCE PER PAPER:\n",
      "     N plos: 6617   N  ref: 177852  N records: 212655\n",
      "\n",
      "\n",
      "citation bins for the selected plos: [0.1, 0.9, 1]\n",
      "\n",
      "bins for PLOS papers:\n",
      "  0-5   N: 16930   avg # ref: 40.9208074534\n",
      "  5-50   N: 148691   avg # ref: 47.5238274628\n",
      "  50-1173   N: 20971   avg # ref: 50.1719457014\n",
      "string for bottom: [0-5] citations  string for top: [50-1173] citations\n",
      "\n",
      "\n",
      "citation bins for the references in the selected plos: [0.1, 0.9, 1] [(0.1, 18.0), (0.9, 426.0), (1.0, 326393.0)]\n",
      "\n",
      "bins for refrences:\n",
      "  0-18 N: 16447   avg # ref: 67.7423846294\n",
      "  18-426 N: 143615   avg # ref: 59.9671273892\n",
      "  426-326393 N: 17789   avg # ref: 54.4957558041\n",
      "\n",
      "\n",
      "# UTs top 10.0 % plos: 663\n",
      "# UTs top 10.0 % ref: 17789\n",
      "# UTs bottom  10.0 % plos: 644\n",
      "# UTs bottom  10.0 % ref: 16447\n",
      "Tot # records: 212655 , # plos: 6617\n",
      "fraction of usage of top ref by \n",
      "  top 10.0 % plos: 0.1384816899838359\n",
      "  bottom 10.0 % plos: 0.07912045036508555\n",
      "fraction of usage of non-top ref by \n",
      "  top 10.0 % plos: 0.06856628674265147\n",
      "  bottom 10.0 % plos: 0.10767846430713857\n",
      "list_lists created: 151086  without structure: 212655    flat_list: 212655\n",
      "len list_lists_all_ref: 151086 (212655, 34)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "plos category:  Biology and life sciences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "avg randomized!!\n",
      "fraction of usage of top ref by\n",
      "  top 10.0 % plos: 0.107584582799\n",
      "  bottom 10.0 % plos: 0.0823460230756\n",
      "\n",
      "\n",
      "avg randomized\n",
      "fraction of usage of non-top ref by \n",
      "  top 10.0 % plos: 0.10725374925\n",
      "  bottom 10.0 % plos: 0.0819874025195 \n",
      "\n",
      "\n",
      "\n",
      "zscore top ref cited  by top plos: 19.6908433181\n",
      "zscore bottom ref cited  by top plos: -16.499279302\n",
      "zscore top ref cited  by bottom plos: -2.08501202997\n",
      "zscore bottom ref cited  by bottom plos: 11.3841335599\n",
      "original size: (5787630, 34)\n",
      "[2011]\n",
      "size of preselection1 (by plos years): (564251, 34)\n",
      "size of preselection1 (by isolated/group ref): (564251, 34) \n",
      " size of preselection (by plos ONE subject category): (528594, 34)  Biology and life sciences\n",
      " size of preselection2 (by plos journal): (528594, 34) \n",
      " size of preselection2 (by plos field): (528594, 34) \n",
      "     N plos: 13477   N  ref: 339696  N records: 528594\n",
      "OJO!!! EACH REFERENCE ONLY COUNTED ONCE PER PAPER:\n",
      "     N plos: 13477   N  ref: 339696  N records: 438207\n",
      "\n",
      "\n",
      "citation bins for the selected plos: [0.1, 0.9, 1]\n",
      "\n",
      "bins for PLOS papers:\n",
      "  0-4   N: 32083   avg # ref: 41.2131687243\n",
      "  4-37   N: 287206   avg # ref: 47.5549228508\n",
      "  37-856   N: 42845   avg # ref: 51.2716678806\n",
      "string for bottom: [0-4] citations  string for top: [37-856] citations\n",
      "\n",
      "\n",
      "citation bins for the references in the selected plos: [0.1, 0.9, 1] [(0.1, 16.0), (0.9, 351.0), (1.0, 326393.0)]\n",
      "\n",
      "bins for refrences:\n",
      "  0-16 N: 30829   avg # ref: 54.9616594765\n",
      "  16-351 N: 274796   avg # ref: 55.2204362509\n",
      "  351-326393 N: 34070   avg # ref: 53.6065453478\n",
      "\n",
      "\n",
      "# UTs top 10.0 % plos: 1373\n",
      "# UTs top 10.0 % ref: 34070\n",
      "# UTs bottom  10.0 % plos: 1215\n",
      "# UTs bottom  10.0 % ref: 30829\n",
      "Tot # records: 438207 , # plos: 13477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of usage of top ref by \n",
      "  top 10.0 % plos: 0.1307634164777022\n",
      "  bottom 10.0 % plos: 0.07369614512471655\n",
      "fraction of usage of non-top ref by \n",
      "  top 10.0 % plos: 0.07484619553090434\n",
      "  bottom 10.0 % plos: 0.09881737910809346\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9c4b590870b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;31m#### first i get the list of lists corresponding to the references used in the selected df, preserving the reference grouping or isolation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mlista_lists_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_list_lists_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreselection_df3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"len list_lists_all_ref:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista_lists_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreselection_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1cf278fbf4a8>\u001b[0m in \u001b[0;36mget_list_lists_references\u001b[0;34m(preselection_df3)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m### first i take care of the isolated references:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgroup_df1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgroup_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isolated_citation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup_df1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2173\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   2149\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   2151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4262\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4263\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4264\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   4148\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4149\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4150\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4148\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4149\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4150\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1221\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# check for promotion based on types only (do this first because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m             \u001b[0;31m# it's faster than computing a mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                 \u001b[0;31m# check if promotion is actually required based on indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/psy/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_promote\u001b[0;34m(dtype, fill_value)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetimetz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#######################  MORE SOPHISTICATED RANDOMIZATION SCHEME: ALSO CONTROLING FOR PLOS FIELD  (AS WELL AS PLOS YEAR)  AND PRESERVING REFERENCES THAT ARE CITED TOGETHER IN A GROUP\n",
    "############################################## ####################### ####################### ####################### ####################### ####################### \n",
    "\n",
    "\n",
    "### Figure 4A\n",
    "\n",
    "\n",
    "\n",
    "#### (i compare the usage of top/nontop references by top/nontop plos papers with a null model that comes from randomizing the data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### (i compare the usafe of top/nontop references by top/nontop plos papers with a null model that comes from randomizing the data)\n",
    "\n",
    "Niter=1000\n",
    "\n",
    "list_list_years = [[2008],[2009],[2010],[2011],[2012],[2013],[2014]]\n",
    "\n",
    "#years=[2008]\n",
    "    \n",
    "for years in list_list_years:\n",
    "   \n",
    "\n",
    "    string_references_age=\"all\"   #young\"#old\"  # young # all   for the selection of what references i include\n",
    "    string_isolated_ref=\"\"  #\"\"   # 0  or 1 (or empty string, to include all ref)\n",
    "    string_self_ref=0    #\"\"#1   # 0  or 1 (or empty string, to include all ref)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### plos ONE categories. \n",
    "    string_code_categ=\"0\" #  ojo!!! the codes are strings, not integers. if i want to include multiple subjects:  \"1 2 8\"\n",
    "\n",
    "    #  '0': 'Biology and life sciences'             6,032,537\n",
    "    #  '1': 'Computer and information sciences'     1,207,799\n",
    "    #  '10': 'Social sciences'                      755,899\n",
    "    #  '2': 'Earth sciences'                        533,155\n",
    "    #  '3': 'Ecology and environmental sciences'    624,142\n",
    "    #  '4': 'Engineering and technology'            382,247 \n",
    "    #  '5': 'Medicine and health sciences'          4,535,926   \n",
    "    #  '6': 'People and places'                     691,523\n",
    "    #  '7': 'Physical sciences'                     2,100,827\n",
    "    #  '8': 'Research and analysis methods'         3,871,470\n",
    "    #  '9': 'Science policy'                        43,360 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # for string_code_categ in range(11):\n",
    "    #     string_code_categ = str(string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### plos journals \n",
    "    string_journal=\"\"\n",
    "\n",
    "        # PLOS ONE       6,367,070\n",
    "        # PLOS GENET      149,923\n",
    "        # PLO NE TR D     138,289   # (neglected tropical diseases)\n",
    "        # PLOS PATHOG     109,803\n",
    "        # PLOS COMPUT      77,924\n",
    "        # PLOS BIOL        56,754\n",
    "        # PLOS MED         24,506\n",
    "\n",
    "\n",
    "\n",
    "    ######### WoS subject categories. \n",
    "    string_plos_field=\"\"#['D CU BIOLOGY']\"\n",
    "\n",
    "    # ['D RO MULTIDISCIPLINARY SCIENCES']                                                                                                       4464540\n",
    "    # ['D CU BIOLOGY']                                                                                                                          1055045\n",
    "    # ['D RO MULTIDISCIPLINARY SCIENCES', 'D CU BIOLOGY']                                                                                        847485\n",
    "    # ['D KM GENETICS & HEREDITY']                                                                                                               149923\n",
    "    # ['D YU TROPICAL MEDICINE', 'D TI PARASITOLOGY']                                                                                            138289\n",
    "    # ['D ZE VIROLOGY', 'D QU MICROBIOLOGY', 'D TI PARASITOLOGY']                                                                                109803\n",
    "    # ['D CO BIOCHEMICAL RESEARCH METHODS', 'D MC MATHEMATICAL & COMPUTATIONAL BIOLOGY']                                                          77687\n",
    "    # ['D CQ BIOCHEMISTRY & MOLECULAR BIOLOGY', 'D CU BIOLOGY']                                                                                   56754\n",
    "    # ['D PY MEDICINE, GENERAL & INTERNAL']                                                                                                       24506\n",
    "    # ['D CO BIOCHEMICAL RESEARCH METHODS', 'D MC MATHEMATICAL & COMPUTATIONAL BIOLOGY', 'D PO MATHEMATICS, INTERDISCIPLINARY APPLICATIONS']        237\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"original size:\",df_merged.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### preselection by plos year\n",
    "    print (years)\n",
    "    preselection_df = df_merged[df_merged['plos_pub_year'].isin(years)]  \n",
    "    print (\"size of preselection1 (by plos years):\",preselection_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### i remove self-citations\n",
    "    if (string_self_ref==0) or  ( string_self_ref == 1 ): \n",
    "        preselection_df = preselection_df[preselection_df['self_citation']== string_self_ref ]  \n",
    "        if string_self_ref ==0:\n",
    "            string_self_ref = \", no self-cit\"\n",
    "        elif string_self_ref ==1:\n",
    "            string_self_ref = \", only self-cit\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by isolated or group references:\n",
    "    if (string_isolated_ref==0) or  ( string_isolated_ref == 1 ): \n",
    "        preselection_df0 = preselection_df[preselection_df['isolated_citation']== string_isolated_ref ]  \n",
    "\n",
    "        if string_isolated_ref ==0:\n",
    "            string_isolated_ref = \", group ref\"\n",
    "        elif string_isolated_ref ==1:\n",
    "            string_isolated_ref = \", isolated ref\"\n",
    "    else:    \n",
    "        preselection_df0 = preselection_df   \n",
    "        print (\"size of preselection1 (by isolated/group ref):\",preselection_df0.shape, string_isolated_ref)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by plos ONE subject category:\n",
    "    if string_code_categ==\"\": \n",
    "        preselection_df111 = preselection_df0\n",
    "    else:    \n",
    "        if \" \" not in string_code_categ:  # to include one single category\n",
    "            preselection_df111 = preselection_df0[preselection_df0['categ_codes'].str.contains(string_code_categ)]        \n",
    "            string_code_categ = \" \"+dict_code_categ[string_code_categ]  \n",
    "\n",
    "        else:  # if multiple codes-categories\n",
    "            list_codes = string_code_categ.split(\" \")\n",
    "            print (list_codes)\n",
    "\n",
    "            if len(list_codes) >= 2:              \n",
    "                preselection_df111 = preselection_df0[ preselection_df0['categ_codes'].str.contains('|'.join(list_codes)) ]  # to look for partial matches from a list of strings!!!!!\n",
    "\n",
    "\n",
    "            string_code_categ = \"\" \n",
    "            for code in list_codes:\n",
    "                string_code_categ += \"-\"+dict_code_categ[code] \n",
    "\n",
    "\n",
    "        print (\" size of preselection (by plos ONE subject category):\",preselection_df111.shape, string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by plos journal:\n",
    "    if string_journal==\"\": \n",
    "        preselection_df1 = preselection_df111\n",
    "    else:    \n",
    "        preselection_df1 = preselection_df111[preselection_df111['plos_j1']== string_journal ]  \n",
    "    print (\" size of preselection2 (by plos journal):\",preselection_df1.shape, string_journal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### preselection by plos field:\n",
    "    if string_plos_field==\"\": \n",
    "        preselection_df2 = preselection_df1\n",
    "    else:    \n",
    "        preselection_df2 = preselection_df1[preselection_df1['plos_field']== string_plos_field ]  \n",
    "    print (\" size of preselection2 (by plos field):\",preselection_df2.shape, string_plos_field)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### preselection only young/old references:       \n",
    "    preselection_df3 = preselection_df2\n",
    "    if string_references_age == \"young\":\n",
    "        time_window_age = 1   \n",
    "        preselection_df3 = preselection_df2[preselection_df2['ref_pub_year'] >= (min(years)-time_window_age) ]   \n",
    "\n",
    "        print (\"    size of preselection3 (only young references):\",preselection_df3.shape, string_references_age)\n",
    "\n",
    "    elif string_references_age == \"old\":\n",
    "        time_window_age = 10    \n",
    "        preselection_df3 = preselection_df2[preselection_df2['ref_pub_year'] <= (min(years)-time_window_age) ]   \n",
    "\n",
    "        print (\"    size of preselection3 (only old references):\",preselection_df3.shape,string_references_age )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    N_plos = len(preselection_df3.paper_UT.unique())         \n",
    "    N_ref = len(preselection_df3.reference_UT.unique()) \n",
    "    N_all = len(preselection_df3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"     N plos:\", N_plos,\"  N  ref:\",N_ref, \" N records:\", N_all)        \n",
    "\n",
    "\n",
    "\n",
    "    preselection_df3 = preselection_df3.drop_duplicates(subset=['paper_UT', 'reference_UT'])\n",
    "\n",
    "    print (\"OJO!!! EACH REFERENCE ONLY COUNTED ONCE PER PAPER:\")\n",
    "\n",
    "    N_plos = len(preselection_df3.paper_UT.unique())         \n",
    "    N_ref = len(preselection_df3.reference_UT.unique()) \n",
    "    N_all = len(preselection_df3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"     N plos:\", N_plos,\"  N  ref:\",N_ref, \" N records:\", N_all)        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############## i define quantiles for plos papers (for that subselection, and based on their FINAL number of citations):\n",
    "    list_q_plos=[.1,.9,1]\n",
    "    #list_q_plos=[.05,.95,1]\n",
    "\n",
    "    df_for_quantiles_plos = preselection_df3.drop_duplicates(subset=['paper_UT'])   # ojo!!! dont use preselection_df3 directly because there are REPETITIONS!!!!\n",
    "\n",
    "    quantiles=sorted(list(df_for_quantiles_plos['paper_cite_count'].quantile(list_q_plos).to_dict().items())) #mean 10.68 \n",
    "\n",
    "    print (\"\\n\\ncitation bins for the selected plos:\", list_q_plos)#,quantiles, df_for_quantiles_plos.shape)   \n",
    "\n",
    "    lista_bins_plos=[]\n",
    "    old_value=0\n",
    "    for item in quantiles:\n",
    "        pair=[old_value, int(item[1])]\n",
    "        lista_bins_plos.append(pair)\n",
    "        old_value = int(item[1])\n",
    "\n",
    "    #print (lista_bins_plos, min(preselection_df3['paper_cite_count']), max(preselection_df3['paper_cite_count']))\n",
    "\n",
    "    print (\"\\nbins for PLOS papers:\")\n",
    "\n",
    "    cont = 0\n",
    "    dict_bin_list_plos_UT={}\n",
    "    for item in lista_bins_plos:\n",
    "\n",
    "        minimo = item[0]\n",
    "        maximo = item[1]   \n",
    "\n",
    "        df_select = preselection_df3[(preselection_df3['paper_cite_count'] >= minimo)  &  (preselection_df3['paper_cite_count'] < maximo)]\n",
    "        llave=str(minimo)+\"-\"+str(maximo)\n",
    "        dict_bin_list_plos_UT[llave]= list(df_select.paper_UT.unique())\n",
    "        print (\" \",llave, \"  N:\",len(list(df_select.reference_UT.unique())), \"  avg # ref:\",df_select.drop_duplicates(subset=['paper_UT']).total_refs.mean())\n",
    "        max_key_plos=llave\n",
    "\n",
    "\n",
    "        if cont ==0:\n",
    "            min_key_plos = llave\n",
    "            string_range_bottom_plos =   \"[\"+llave+\"] citations\"\n",
    "\n",
    "\n",
    "        cont  +=1\n",
    "\n",
    "\n",
    "\n",
    "        string_range_top_plos =  \"[\"+llave+\"] citations\"  \n",
    "\n",
    "    print (\"string for bottom:\", string_range_bottom_plos, \" string for top:\", string_range_top_plos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########## i define quantiles for references (based on their FINAL number of citations)\n",
    "    #list_q_ref=[.2,.8,1]\n",
    "    list_q_ref=[.1,.9,1]\n",
    "\n",
    "    #list_q_ref=[.05,.95,1]\n",
    "    df_for_quantiles_ref = preselection_df3.drop_duplicates(subset=['reference_UT'])   # ojo!!! remember to remove REPETITIONS!!!!\n",
    "    quantiles=sorted(list(df_for_quantiles_ref['cite_count'].quantile(list_q_ref).to_dict().items())) #mean 10.68 \n",
    "\n",
    "    print (\"\\n\\ncitation bins for the references in the selected plos:\", list_q_ref,quantiles)    \n",
    "\n",
    "    lista_bins=[]\n",
    "    old_value=0\n",
    "    for item in quantiles:\n",
    "        pair=[old_value, int(item[1])]\n",
    "        lista_bins.append(pair)\n",
    "        old_value = int(item[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\nbins for refrences:\")\n",
    "\n",
    "\n",
    "    cont = 0\n",
    "    dict_bin_list_ref_UT={}\n",
    "    for item in lista_bins:\n",
    "\n",
    "        minimo = item[0]\n",
    "        maximo = item[1]    \n",
    "\n",
    "        df_select = preselection_df3[(preselection_df3['cite_count'] >= minimo)  &  (preselection_df3['cite_count'] < maximo)]\n",
    "        llave=str(minimo)+\"-\"+str(maximo)\n",
    "        dict_bin_list_ref_UT[llave]=list(df_select.reference_UT.unique())\n",
    "        print (\" \",llave, \"N:\",len(list(df_select.reference_UT.unique())), \"  avg # ref:\",df_select.drop_duplicates(subset=['reference_UT']).total_refs.mean())\n",
    "        max_key_ref=llave\n",
    "\n",
    "        if cont ==0:\n",
    "            min_key_ref = llave\n",
    "        cont  +=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############### i create the list of top plos, top ref, bottom plos and bottom ref:\n",
    "    #########################\n",
    "\n",
    "    lista_top_plos = dict_bin_list_plos_UT[max_key_plos]\n",
    "    print (\"\\n\\n# UTs top\",(100-100*list_q_plos[-2]),\"% plos:\",len(lista_top_plos))\n",
    "\n",
    "    lista_top_ref=dict_bin_list_ref_UT[max_key_ref]\n",
    "    print (\"# UTs top\",(100-100*list_q_ref[-2]),\"% ref:\", len(lista_top_ref))\n",
    "\n",
    "\n",
    "    lista_bottom_plos = dict_bin_list_plos_UT[min_key_plos]\n",
    "    print (\"# UTs bottom \",(100*list_q_plos[0]),\"% plos:\",len(lista_bottom_plos))\n",
    "\n",
    "    lista_bottom_ref=dict_bin_list_ref_UT[min_key_ref]\n",
    "    print (\"# UTs bottom \",(100*list_q_ref[0]),\"% ref:\", len(lista_bottom_ref))\n",
    "\n",
    "    list_plos_in_year= list(preselection_df3.paper_UT.unique())\n",
    "    print (\"Tot # records:\",len(preselection_df3),\", # plos:\",len(list_plos_in_year))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######  i look at the usage of the top ref\n",
    "    ################################################  \n",
    "\n",
    "    df_top_ref = preselection_df3[preselection_df3['reference_UT'].isin(lista_top_ref)]\n",
    "\n",
    "\n",
    "    df_top_ref_top_plos = df_top_ref[df_top_ref['paper_UT'].isin(lista_top_plos)]\n",
    "    df_top_ref_bottom_plos = df_top_ref[df_top_ref['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "\n",
    "    usage_top_ref_top_plos = len(df_top_ref_top_plos)/float(len(df_top_ref))\n",
    "    usage_top_ref_bottom_plos = len(df_top_ref_bottom_plos)/float(len(df_top_ref))\n",
    "\n",
    "\n",
    "    print (\"fraction of usage of top ref by \")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\",  usage_top_ref_top_plos)\n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\",usage_top_ref_bottom_plos  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######  i look at the usage of the non-top ref\n",
    "    ################################################      \n",
    "\n",
    "    df_non_top_ref = preselection_df3[preselection_df3['reference_UT'].isin(lista_bottom_ref)]\n",
    "\n",
    "\n",
    "    df_non_top_ref_top_plos = df_non_top_ref[df_non_top_ref['paper_UT'].isin(lista_top_plos)]\n",
    "    df_non_top_ref_bottom_plos = df_non_top_ref[df_non_top_ref['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "    usage_non_top_ref_top_plos = len(df_non_top_ref_top_plos)/float(len(df_non_top_ref))\n",
    "    usage_non_top_ref_bottom_plos = len(df_non_top_ref_bottom_plos)/float(len(df_non_top_ref))\n",
    "\n",
    "\n",
    "    print (\"fraction of usage of non-top ref by \")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\", usage_non_top_ref_top_plos )\n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\", usage_non_top_ref_bottom_plos )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####################\n",
    "    # I canculate the null model (usage of references by top and non top plos papers, from the randomized data)\n",
    "    #################################################  \n",
    "\n",
    "    lista_usage_top_ref_by_top_plos_rand = []\n",
    "    lista_usage_top_ref_by_bottom_plos_rand = []\n",
    "\n",
    "    lista_usage_nontop_ref_by_top_plos_rand = []\n",
    "    lista_usage_nontop_ref_by_bottom_plos_rand = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### first i get the list of lists corresponding to the references used in the selected df, preserving the reference grouping or isolation:  \n",
    "    lista_lists_values = get_list_lists_references(preselection_df3)\n",
    "\n",
    "    print (\"len list_lists_all_ref:\",len(lista_lists_values), preselection_df3.shape)\n",
    "\n",
    "\n",
    "    for i in range(Niter):\n",
    "\n",
    "        print (i)\n",
    "\n",
    "\n",
    "\n",
    "        #### old, simple randomization scheme (only controling for year)\n",
    "    #     lista_values = list(preselection_df3.reference_UT)   #[i for i in range (len(df_merged))]\n",
    "    #     random.shuffle(lista_values)\n",
    "    #     preselection_df3['randomized_ref_UT'] = lista_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ########   new randomization scheme (controling for year, but also preserving groups of references cited together in a paper):   \n",
    "        #### lista_values is created outside the Niter loop   (i only need to do it once per selected df)    \n",
    "\n",
    "\n",
    "\n",
    "        random.shuffle(lista_lists_values)      \n",
    "        ### to flat out a list of lists:   \n",
    "        flat_list = []    \n",
    "        for sublist in lista_lists_values:\n",
    "            for item in sublist:\n",
    "                flat_list.append(item)\n",
    "\n",
    "\n",
    "       # print (\"len flat list:\", len(flat_list), preselection_df3.shape)\n",
    "\n",
    "        preselection_df3['randomized_ref_UT'] = flat_list   ### ojo!!! esto randomiza paper_UT, no reference_UT  !!!!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ####### (RANDOMIZED)  i look at the usage of the top ref\n",
    "        df_top_ref_rand = preselection_df3[preselection_df3['randomized_ref_UT'].isin(lista_top_ref)]\n",
    "\n",
    "        df_top_ref_top_plos_rand = df_top_ref_rand[df_top_ref_rand['paper_UT'].isin(lista_top_plos)]\n",
    "        df_top_ref_bottom_plos_rand = df_top_ref_rand[df_top_ref_rand['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "\n",
    "        usage_top_ref_top_plos_rand = len(df_top_ref_top_plos_rand)/float(len(df_top_ref_rand))\n",
    "        usage_top_ref_bottom_plos_rand = len(df_top_ref_bottom_plos_rand)/float(len(df_top_ref_rand))\n",
    "\n",
    "\n",
    "        lista_usage_top_ref_by_top_plos_rand.append(usage_top_ref_top_plos_rand)\n",
    "        lista_usage_top_ref_by_bottom_plos_rand.append(usage_top_ref_bottom_plos_rand)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #######  (RANDOMIZED) i look at the usage of the non-top ref            \n",
    "        df_non_top_ref_rand = preselection_df3[preselection_df3['randomized_ref_UT'].isin(lista_bottom_ref)]        \n",
    "\n",
    "        df_non_top_ref_top_plos_rand = df_non_top_ref_rand[df_non_top_ref_rand['paper_UT'].isin(lista_top_plos)]\n",
    "        df_non_top_ref_bottom_plos_rand = df_non_top_ref_rand[df_non_top_ref_rand['paper_UT'].isin(lista_bottom_plos)]\n",
    "\n",
    "\n",
    "        usage_non_top_ref_top_plos_rand = len(df_non_top_ref_top_plos_rand)/float(len(df_non_top_ref_rand))\n",
    "        usage_non_top_ref_bottom_plos_rand = len(df_non_top_ref_bottom_plos_rand)/float(len(df_non_top_ref_rand))\n",
    "\n",
    "\n",
    "        lista_usage_nontop_ref_by_top_plos_rand.append(usage_non_top_ref_top_plos_rand)\n",
    "        lista_usage_nontop_ref_by_bottom_plos_rand.append(usage_non_top_ref_bottom_plos_rand)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"plos category:\", string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\n\\n\\n\\navg randomized!!\")\n",
    "    print(\"fraction of usage of top ref by\")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\",  np.mean(lista_usage_top_ref_by_top_plos_rand) )   \n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\",np.mean(lista_usage_top_ref_by_bottom_plos_rand)  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\n\\navg randomized\")\n",
    "    print (\"fraction of usage of non-top ref by \")\n",
    "    print (\"  top\",(100-100*list_q_plos[-2]),\"% plos:\", np.mean(lista_usage_nontop_ref_by_top_plos_rand) )   \n",
    "    print (\"  bottom\",(100*list_q_plos[0]),\"% plos:\", np.mean(lista_usage_nontop_ref_by_bottom_plos_rand) ,\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #############################  second part\n",
    "\n",
    "\n",
    "    ###  PLOT FIGURE FOR MORE SOPHISTICATED VERSION OF THE RANDOMIZATION SCHEME\n",
    "    ######     (RUN PREVIOUS CELL FIRST, TO GET THE BOOT-STRAPPING DATA)\n",
    "\n",
    "\n",
    "    ### group by Top PApers  Bottom Papers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    #lista_bin_names=['Top '+str(int(100-100*list_q_plos[-2]))+'%<br>papers', 'Bottom '+str(int(list_q_plos[0]*100))+'%<br>papers']\n",
    "    #lista_bin_names = ['Bottom '+str(int(list_q_plos[0]*100))+'%<br>papers', 'Top '+str(int(100-100*list_q_plos[-2]))+'%<br>papers']\n",
    "\n",
    "    lista_bin_names = ['Bottom '+str(int(list_q_plos[0]*100))+'% papers<br>'+string_range_bottom_plos, 'Top '+str(int(100-100*list_q_plos[-2]))+'% papers<br>'+string_range_top_plos]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lista_for_top_ref = [ usage_top_ref_top_plos, usage_top_ref_bottom_plos]\n",
    "    lista_for_bottom_ref = [usage_non_top_ref_top_plos, usage_non_top_ref_bottom_plos]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lista_for_top_ref = [  usage_top_ref_bottom_plos, usage_top_ref_top_plos]\n",
    "    lista_for_bottom_ref = [usage_non_top_ref_bottom_plos, usage_non_top_ref_top_plos]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###### this is the null model \n",
    "\n",
    "\n",
    "    # lista_expectations_top_ref = [np.mean(lista_usage_top_ref_by_top_plos_rand),np.mean(lista_usage_top_ref_by_bottom_plos_rand)]  \n",
    "    # lista_expectations_bottom_ref = [np.mean(lista_usage_nontop_ref_by_top_plos_rand), np.mean(lista_usage_nontop_ref_by_bottom_plos_rand)] \n",
    "\n",
    "\n",
    "    lista_expectations_top_ref = [np.mean(lista_usage_top_ref_by_bottom_plos_rand), np.mean(lista_usage_top_ref_by_top_plos_rand)]  \n",
    "    lista_expectations_bottom_ref = [ np.mean(lista_usage_nontop_ref_by_bottom_plos_rand),np.mean(lista_usage_nontop_ref_by_top_plos_rand)] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # list_errors_top_ref = [2.*np.std(lista_usage_top_ref_by_top_plos_rand), 2.*np.std(lista_usage_top_ref_by_bottom_plos_rand)] \n",
    "    # list_errors_bottom_ref = [2.*np.std(lista_usage_nontop_ref_by_top_plos_rand) , 2.*np.std(lista_usage_nontop_ref_by_bottom_plos_rand)] \n",
    "\n",
    "\n",
    "    list_errors_top_ref = [2.*np.std(lista_usage_top_ref_by_bottom_plos_rand), 2.*np.std(lista_usage_top_ref_by_top_plos_rand) ] \n",
    "    list_errors_bottom_ref = [2.*np.std(lista_usage_nontop_ref_by_bottom_plos_rand), 2.*np.std(lista_usage_nontop_ref_by_top_plos_rand) ] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    z_score_top_ref_by_top_plos = (usage_top_ref_top_plos - np.mean(lista_usage_top_ref_by_top_plos_rand))/np.std(lista_usage_top_ref_by_top_plos_rand)\n",
    "    z_score_nontop_ref_by_top_plos = (usage_non_top_ref_top_plos - np.mean(lista_usage_nontop_ref_by_top_plos_rand))/np.std(lista_usage_nontop_ref_by_top_plos_rand)\n",
    "\n",
    "    z_score_top_ref_by_bottom_plos = (usage_top_ref_bottom_plos - np.mean(lista_usage_top_ref_by_bottom_plos_rand))/np.std(lista_usage_top_ref_by_bottom_plos_rand)\n",
    "    z_score_nontop_ref_by_bottom_plos = (usage_non_top_ref_bottom_plos - np.mean(lista_usage_nontop_ref_by_bottom_plos_rand))/np.std(lista_usage_nontop_ref_by_bottom_plos_rand)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print ('zscore top ref cited  by top plos:', z_score_top_ref_by_top_plos)\n",
    "    print ('zscore bottom ref cited  by top plos:', z_score_nontop_ref_by_top_plos)\n",
    "\n",
    "    print ('zscore top ref cited  by bottom plos:', z_score_top_ref_by_bottom_plos)\n",
    "    print ('zscore bottom ref cited  by bottom plos:', z_score_nontop_ref_by_bottom_plos)\n",
    "\n",
    "\n",
    "\n",
    "    title_string=''#'s top-ref by top plos: '+str(z_score_top_ref_by_top_plos)+';  zs top-ref by bottom plos: '+str(z_score_top_ref_by_bottom_plos)+\\\n",
    "    #'<br>zs nontop-ref by top plos: '+str(z_score_nontop_ref_by_top_plos)+';  zs nontop-ref by bottom plos: '+str(z_score_nontop_ref_by_bottom_plos)\n",
    "\n",
    "\n",
    "\n",
    "    size_bar_name = 30#45\n",
    "    y_pos_bar_names = -.039\n",
    "    angle = -70\n",
    "\n",
    "    trace1 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_for_top_ref,\n",
    "    #     text=['by top '+str(int(100-100*list_q_plos[-2]))+'% papers', 'by top '+str(int(100-100*list_q_plos[-2]))+'% papers'],    \n",
    "    #     name='by top '+str(int(100-100*list_q_plos[-2]))+'% papers',   \n",
    "        marker=dict(\n",
    "            color='#88419d',           \n",
    "        ),\n",
    "\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    trace2 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_expectations_top_ref,\n",
    "    #     name='   expected value',\n",
    "    #     text=['Expected value for top', 'Expected value for top'],  \n",
    "        error_y=dict(\n",
    "           # type='data',\n",
    "            array=list_errors_top_ref,\n",
    "            thickness=5,\n",
    "            visible=True\n",
    "        ),\n",
    "        marker=dict(\n",
    "            color='#c994c7',         \n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "    trace3 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_for_bottom_ref,\n",
    "    #     name='by bottom '+str(int(list_q_plos[0]*100))+'% papers', \n",
    "    #     text=['by bottom '+str(int(list_q_plos[0]*100))+'% papers','by bottom '+str(int(list_q_plos[0]*100))+'% papers'],\n",
    "        marker=dict(\n",
    "            color='#225ea8',   \n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "    trace4 = go.Bar(\n",
    "        x=lista_bin_names,\n",
    "        y=lista_expectations_bottom_ref,\n",
    "      #  name='   expected value',\n",
    "\n",
    "        error_y=dict(       \n",
    "            array=list_errors_bottom_ref,#[0.5, 1, 2],\n",
    "            thickness=5,\n",
    "            visible=True\n",
    "        ),\n",
    "        marker=dict(\n",
    "            color='#a6bddb',     \n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data = [trace1, trace2, trace3, trace4]\n",
    "    layout = go.Layout(   \n",
    "        title=title_string,\n",
    "        xaxis = dict(\n",
    "            side= 'top',\n",
    "            range = [-.5,1.5],\n",
    "           # showline =  True,\n",
    "            #title= 'Plos Citation percentile'),\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title= 'Fraction references cited',\n",
    "            range = [-.07,0.17],\n",
    "            tickvals=[0.0,0.05,0.1,0.15],\n",
    "            #showline =  True,\n",
    "             ),\n",
    "\n",
    "        showlegend=False,\n",
    "    #     legend=dict(x=0.75, y=1.05,                 \n",
    "    #                font=dict(\n",
    "    #                     #family='sans-serif',\n",
    "    #                     size=40,\n",
    "    #                     #color='#000'\n",
    "    #                     ),\n",
    "    #                 ),\n",
    "\n",
    "\n",
    "    #     barmode='stacked',#group',\n",
    "       # bargap=0.2,\n",
    "        bargroupgap=0.15,\n",
    "\n",
    "        annotations = [  \n",
    "            # the four bars on the left\n",
    "            dict(\n",
    "              x = -.34,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Top '+str(int(100-100*list_q_ref[-2]))+'%<br>references',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),    \n",
    "            dict(\n",
    "              x = -0.14,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Null Model',\n",
    "               textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = .08,\n",
    "              y = y_pos_bar_names,\n",
    "              showarrow = False,\n",
    "              text = 'Bottom '+str(int(list_q_ref[0]*100))+'%<br>references', \n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = .28,\n",
    "              y = y_pos_bar_names,\n",
    "              text =  'Null Model',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "\n",
    "\n",
    "\n",
    "            # the four bars on the right\n",
    "            dict(  \n",
    "              x = .68,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Top '+str(int(100-100*list_q_ref[-2]))+'%<br>references',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = .88,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Null Model',\n",
    "               textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = 1.08,\n",
    "              y = y_pos_bar_names,\n",
    "              text = 'Bottom '+str(int(list_q_ref[0]*100))+'%<br>references', \n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "            dict(\n",
    "              x = 1.28,\n",
    "              y = y_pos_bar_names,\n",
    "              text =  'Null Model',\n",
    "              textangle=angle,\n",
    "                font = dict(size = size_bar_name ),\n",
    "               ),\n",
    "\n",
    "\n",
    "            ],    \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    font_gral=55  # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "    fig['layout']['font']['size'] = font_gral-5\n",
    "\n",
    "\n",
    "    # Altering x axis\n",
    "    #fig['layout']['xaxis']['tickfont']['family'] = 'Gill Sans MT'\n",
    "    fig['layout']['xaxis']['tickangle'] = 0\n",
    "    # fig['layout']['yaxis']['tickangle'] = -90\n",
    "    # fig['layout']['xaxis']['titlefont']['size'] = font_gral -10\n",
    "    # fig['layout']['yaxis']['titlefont']['size'] = font_gral -10\n",
    "\n",
    "    fig['layout']['xaxis']['tickfont']['size'] = font_gral -5\n",
    "    fig['layout']['yaxis']['tickfont']['size'] = font_gral -10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig['layout']['margin']=dict(\n",
    "            l=300,\n",
    "           # r=50,\n",
    "            b=100,\n",
    "            t=200,\n",
    "            pad=15\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    py.iplot(fig, filename='grouped-bar')\n",
    "\n",
    "\n",
    "    fig_filename='fract_usage_top_bottom_ref_'+str(years[0])+string_code_categ.replace(\" \",\"_\")\n",
    "    offline.plot(fig, auto_open=True, image = 'png', image_filename='../plots/'+fig_filename ,image_width=2000, image_height=1200, filename='../plots/'+fig_filename+'.html', validate=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # earth science, 2013, 1000 iter, simple randomization scheme:\n",
    "\n",
    "    # zscore top ref cited  by top plos: 1.8633822051\n",
    "    # zscore bottom ref cited  by top plos: -8.29803601221\n",
    "    # zscore top ref cited  by bottom plos: -4.18320566755\n",
    "    # zscore bottom ref cited  by bottom plos: 2.22458205576\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## earth science, 2013, 1000 iter, more sophisticated randomization scheme (preserving reference groups/isolated references):\n",
    "\n",
    "    # zscore top ref cited  by top plos: 1.61069883113\n",
    "    # zscore bottom ref cited  by top plos: -8.02168733553\n",
    "    # zscore top ref cited  by bottom plos: -3.84738913187\n",
    "    # zscore bottom ref cited  by bottom plos: 2.16556097748\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2], [2, 8], [8, 25], [25, 79], [79, 1173]] (156558, 58)\n",
      "[0, 2] (156558, 58) (35805, 58) [[(0.25, 0.07407407407407407), (0.5, 0.14705882352941177), (0.75, 0.23809523809523808)], [(0.25, 0.0), (0.5, 0.04395604395604396), (0.75, 0.0975609756097561)], [(0.25, 0.0), (0.5, 0.0), (0.75, 0.02857142857142857)], [(0.25, 0.029411764705882353), (0.5, 0.11363636363636363), (0.75, 0.20930232558139536)]]\n",
      "[2, 8] (156558, 58) (57980, 58) [[(0.25, 0.06521739130434782), (0.5, 0.13043478260869565), (0.75, 0.2127659574468085)], [(0.25, 0.0), (0.5, 0.04081632653061224), (0.75, 0.08695652173913043)], [(0.25, 0.0), (0.5, 0.0), (0.75, 0.0425531914893617)], [(0.25, 0.03333333333333333), (0.5, 0.10714285714285714), (0.75, 0.1935483870967742)]]\n",
      "[8, 25] (156558, 58) (46718, 58) [[(0.25, 0.04838709677419355), (0.5, 0.10416666666666667), (0.75, 0.17777777777777778)], [(0.25, 0.0), (0.5, 0.03571428571428571), (0.75, 0.07692307692307693)], [(0.25, 0.0), (0.5, 0.0), (0.75, 0.04878048780487805)], [(0.25, 0.02564102564102564), (0.5, 0.08695652173913043), (0.75, 0.1643835616438356)]]\n",
      "[25, 79] (156558, 58) (14457, 58) [[(0.25, 0.02857142857142857), (0.5, 0.07317073170731707), (0.75, 0.1346153846153846)], [(0.25, 0.0), (0.5, 0.02857142857142857), (0.75, 0.06451612903225806)], [(0.25, 0.0), (0.5, 0.0), (0.75, 0.047619047619047616)], [(0.25, 0.0), (0.5, 0.058823529411764705), (0.75, 0.125)]]\n",
      "[79, 1173] (156558, 58) (1597, 58) [[(0.25, 0.0), (0.5, 0.047619047619047616), (0.75, 0.09803921568627451)], [(0.25, 0.0), (0.5, 0.022727272727272728), (0.75, 0.058823529411764705)], [(0.25, 0.0), (0.5, 0.0), (0.75, 0.04225352112676056)], [(0.25, 0.0), (0.5, 0.03125), (0.75, 0.08823529411764706)]]\n",
      "[[16.879999999999999, 6.5599999999999996, 2.6000000000000001, 13.550000000000001], [15.01, 5.9500000000000002, 3.0800000000000001, 12.720000000000001], [12.41, 5.2300000000000004, 3.2799999999999998, 10.779999999999999], [9.3300000000000001, 4.4100000000000001, 3.21, 8.0700000000000003], [6.8099999999999996, 3.9500000000000002, 2.9100000000000001, 5.75]]\n",
      "\n",
      "\n",
      "\n",
      "[[16.899999999999999, 6.5999999999999996, 2.6000000000000001, 13.6], [15.0, 6.0, 3.1000000000000001, 12.699999999999999], [12.4, 5.2000000000000002, 3.2999999999999998, 10.800000000000001], [9.3000000000000007, 4.4000000000000004, 3.2000000000000002, 8.0999999999999996], [6.7999999999999998, 4.0, 2.8999999999999999, 5.7999999999999998]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/staff/julia/at_Northwestern/In_Text_Citations/In-Text-Citations-New/notebooks/testing_annotated_heatmap_color.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
