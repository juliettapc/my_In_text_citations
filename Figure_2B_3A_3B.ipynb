{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#Due to leftoevererrors in Nathan's python installation, some cleaning up occurs here\n",
    "#sys.path.append(\"./code/\")\n",
    "#sys.path.remove('/usr/local/lib/python2.7/site-packages') \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import datetime\n",
    "import pickle\n",
    "import gzip\n",
    "import os,glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import random\n",
    "from  scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "import itertools\n",
    "#sys.path\n",
    "\n",
    "\n",
    "import regex as re\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='juliettapc', api_key='nM6iUdx6dGaOiPXQTwpP')   # go to: https://plot.ly/settings/api#/   for a new key if needed\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 790 ms, total: 5.09 s\n",
      "Wall time: 5.09 s\n",
      "done loading pickles (5787634, 34)\n",
      "(156558, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence</th>\n",
       "      <th>reference_UT</th>\n",
       "      <th>reference_rank</th>\n",
       "      <th>regex_sect_index</th>\n",
       "      <th>cite_count</th>\n",
       "      <th>ref_pub_year</th>\n",
       "      <th>paper_cite_count</th>\n",
       "      <th>plos_pub_year</th>\n",
       "      <th>sect_char_pos</th>\n",
       "      <th>sect_char_total</th>\n",
       "      <th>...</th>\n",
       "      <th>plos_article_type</th>\n",
       "      <th>num_cit_young_ref_by2009</th>\n",
       "      <th>num_cit_young_ref_by2010</th>\n",
       "      <th>num_cit_young_ref_by2011</th>\n",
       "      <th>num_cit_young_ref_by2012</th>\n",
       "      <th>num_cit_young_ref_by2013</th>\n",
       "      <th>num_cit_young_ref_by2009after8</th>\n",
       "      <th>num_cit_young_ref_by2008after8</th>\n",
       "      <th>num_cit_young_ref_by2010after8</th>\n",
       "      <th>num_cit_young_ref_by2007after8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>494</td>\n",
       "      <td>5398</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>000263911400006</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>142</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>000289279600018</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>269</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>000289279600018</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3844</td>\n",
       "      <td>5398</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   occurence     reference_UT  reference_rank  regex_sect_index  cite_count  \\\n",
       "0          1  A1995QY75100004               1                 0        60.0   \n",
       "1          2  A1995QY75100004               1                 3        60.0   \n",
       "4          1  000263911400006               3                 0         5.0   \n",
       "5          1  000289279600018               4                 0        29.0   \n",
       "6          3  000289279600018               4                 3        29.0   \n",
       "\n",
       "   ref_pub_year  paper_cite_count  plos_pub_year  sect_char_pos  \\\n",
       "0        1995.0                 2         2013.0            139   \n",
       "1        1995.0                 2         2013.0            494   \n",
       "4        2009.0                 2         2013.0            142   \n",
       "5        2011.0                 2         2013.0            269   \n",
       "6        2011.0                 2         2013.0           3844   \n",
       "\n",
       "   sect_char_total              ...               plos_article_type  \\\n",
       "0             4029              ...                       @ Article   \n",
       "1             5398              ...                       @ Article   \n",
       "4             4029              ...                       @ Article   \n",
       "5             4029              ...                       @ Article   \n",
       "6             5398              ...                       @ Article   \n",
       "\n",
       "  num_cit_young_ref_by2009 num_cit_young_ref_by2010  num_cit_young_ref_by2011  \\\n",
       "0                      NaN                      NaN                       NaN   \n",
       "1                      NaN                      NaN                       NaN   \n",
       "4                      0.0                      0.0                       NaN   \n",
       "5                      0.0                      0.0                       0.0   \n",
       "6                      0.0                      0.0                       0.0   \n",
       "\n",
       "   num_cit_young_ref_by2012  num_cit_young_ref_by2013  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "5                       3.0                       NaN   \n",
       "6                       3.0                       NaN   \n",
       "\n",
       "   num_cit_young_ref_by2009after8 num_cit_young_ref_by2008after8  \\\n",
       "0                             NaN                            NaN   \n",
       "1                             NaN                            NaN   \n",
       "4                             5.0                            5.0   \n",
       "5                            39.0                           39.0   \n",
       "6                            39.0                           39.0   \n",
       "\n",
       "   num_cit_young_ref_by2010after8 num_cit_young_ref_by2007after8  \n",
       "0                             NaN                            NaN  \n",
       "1                             NaN                            NaN  \n",
       "4                             5.0                            5.0  \n",
       "5                            39.0                           39.0  \n",
       "6                            39.0                           39.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                  \n",
    "\n",
    "####  NEW FILE INCLUDING EARLY CITATIONS OF YOUNG REFERENCES:   ../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit.pkl\n",
    "                                            \n",
    "#%time df_merged = pickle.load(open('../data/df_reference_cite_plos_merged_simplified_added_more_columns_no_self-cit_one_ref_per_sect_ONLY_ARTICLES.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "%time df_merged = pickle.load(open('../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit_and_after_accretion_time.pkl', 'rb'))\n",
    "print (\"done loading pickles\", df_merged.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_merged = df_merged[df_merged['cite_count'] != -1]   # i dont know why, but there are 7 occurrences with value -1\n",
    "\n",
    "\n",
    "\n",
    "plos_df = df_merged.drop_duplicates(subset=['paper_UT'])\n",
    "print (plos_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size: (5787630, 34)\n",
      "[2011]\n",
      "size of preselection1 (by plos years): (564251, 34)\n",
      "size of preselection1 (by isolated/group ref): (564251, 34) \n",
      " size of preselection2 (by plos journal): (564251, 34) \n",
      " size of preselection2 (by plos field): (564251, 34) \n",
      "  size of preselection3 (only young references): (183640, 34) only old references from <=2001\n",
      "\n",
      "Tot # records included: 183640    # number of plos papers: 14028    # unique ref: 123212 \n",
      "\n",
      "[[0, 8], [8, 16], [16, 35], [35, 84], [84, 856]]\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]  [ (1,4) x4,y1 ]\n",
      "[ (2,1) x1,y2 ]  [ (2,2) x2,y2 ]  [ (2,3) x3,y2 ]  [ (2,4) x4,y2 ]\n",
      "[ (3,1) x1,y3 ]  [ (3,2) x2,y3 ]  [ (3,3) x3,y3 ]  [ (3,4) x4,y3 ]\n",
      "[ (4,1) x1,y4 ]  [ (4,2) x2,y4 ]  [ (4,3) x3,y4 ]  [ (4,4) x4,y4 ]\n",
      "[ (5,1) x1,y5 ]  [ (5,2) x2,y5 ]  [ (5,3) x3,y5 ]  [ (5,4) x4,y5 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/staff/julia/at_Northwestern/In_Text_Citations/In-Text-Citations-New/plots/multiplot_comparisons.html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#  annotated heatmap plot for median publication year (OR CITATIONS) of the references used in the different sections, and separating by citation category of the plos\n",
    "\n",
    "\n",
    "##### FIGURE 2B  AND FIGURE 3A AND FIGURE 3B and the corresponding pairwise comparisons\n",
    "\n",
    "\n",
    "dict_group_subset_data={}\n",
    "dict_group_quantiles_size={}\n",
    "\n",
    "######### in this cell I SELECT the data i want to plot (by multiple criteria), as well as the variable that will encode with color:\n",
    "######### ######### ######### ######### ######### ######### ######### \n",
    "\n",
    "\n",
    "v1_string = 'cite_count'   #      cite_count    diff_year_plos_ref \n",
    "       \n",
    "  \n",
    "string_references_age = \"old\"#old\"   #\"#old\"  # young # all   for the selection of what references i include\n",
    "  \n",
    "  \n",
    "  \n",
    "top_space = 150\n",
    "if v1_string ==  'cite_count'  :\n",
    "    colorbar_string = 'Citations'\n",
    "    if string_references_age == \"old\" :\n",
    "        colorbar_string = ''\n",
    "else:\n",
    "    colorbar_string = 'Age [yr]'\n",
    "    top_space = 100\n",
    "    text_abc = '(b)'\n",
    "\n",
    "years=[2011] \n",
    "\n",
    "\n",
    "\n",
    "#years=[2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017] \n",
    "\n",
    "\n",
    "\n",
    "list_q=[0.3,0.6,.9,.99,1]    # for the percentile sections for number of citations of the PLOS papers\n",
    " \n",
    "    \n",
    "string_filtering_x = 'paper_cite_count'   # bins by plos' citations on the x-axis ###      \n",
    "  \n",
    "    \n",
    "      \n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "string_isolated_ref = \"\"   #\"\"   #\"  #\"\"   # 0  or 1 (or empty string, to include all ref)\n",
    "#list_strings = [1,0]\n",
    "#for  string_isolated_ref  in list_strings:\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "string_self_ref =0         #\"\"      # \"\"   #1   # 0  or 1 (or empty string, to include all ref)   OJO!!! THIS NEW FILE DOES NOT INCLUDE SELF-CITATIONS TO BEGING WITH\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### plos ONE categories. \n",
    "string_code_categ=\"\" #  ojo!!! the codes are strings, not integers. if i want to include multiple subjects:  \"1 2 8\"\n",
    "\n",
    "\n",
    "#list_strings=['0', '1', '4', '5', '7', '8', '2 3','10 6 9']\n",
    "#for string_code_categ in list_strings:\n",
    "\n",
    "\n",
    "#   Biology and Live Sciences;   Computational Sciences;   Engineering;   Medicine;   Physical Sciences;   Research and Analysis; \\\n",
    "#  Earth Sciences and Ecology;   Social Sciences, Political Sciences and People & Places\n",
    "\n",
    "\n",
    "\n",
    "#  '0': 'Biology and life sciences'             6,032,537 --\n",
    "#  '1': 'Computer and information sciences'     1,207,799 --\n",
    "#  '10': 'Social sciences'                      755,899 --\n",
    "#  '2': 'Earth sciences'                        533,155 --\n",
    "#  '3': 'Ecology and environmental sciences'    624,142 --\n",
    "#  '4': 'Engineering and technology'            382,247 --\n",
    "#  '5': 'Medicine and health sciences'          4,535,926  -- \n",
    "#  '6': 'People and places'                     691,523 --\n",
    "#  '7': 'Physical sciences'                     2,100,827 --\n",
    "#  '8': 'Research and analysis methods'         3,871,470 --\n",
    "#  '9': 'Science policy'                        43,360 --\n",
    "\n",
    "\n",
    "######### plos journals \n",
    "string_journal=\"\"#   PLOS ONE\"\n",
    "\n",
    "#list_strings=['PLOS MED', 'PLOS BIOL', 'PLOS COMPUT', 'PLOS PATHOG', 'PLO NE TR D', 'PLOS GENET', 'PLOS ONE']\n",
    "\n",
    "\n",
    "#for string_journal in list_strings:\n",
    "\n",
    "    # PLOS ONE       6,367,070\n",
    "    # PLOS GENET      149,923\n",
    "    # PLO NE TR D     138,289   # (neglected tropical diseases)\n",
    "    # PLOS PATHOG     109,803\n",
    "    # PLOS COMPUT      77,924\n",
    "    # PLOS BIOL        56,754\n",
    "    # PLOS MED         24,506\n",
    "\n",
    "\n",
    "\n",
    "#PLOS Medicine, PLOS Biol-ogy, PLOS Computational Biology, PLOS Pathology, PLOS Neglected Tropical Diseases, PLOSGenetics, and PLOS ONE\n",
    "\n",
    "\n",
    "######### WoS subject categories. \n",
    "string_plos_field=\"\"#['D CU BIOLOGY']\"\n",
    "\n",
    "# ['D RO MULTIDISCIPLINARY SCIENCES']                                                                                                       4464540\n",
    "# ['D CU BIOLOGY']                                                                                                                          1055045\n",
    "# ['D RO MULTIDISCIPLINARY SCIENCES', 'D CU BIOLOGY']                                                                                        847485\n",
    "# ['D KM GENETICS & HEREDITY']                                                                                                               149923\n",
    "# ['D YU TROPICAL MEDICINE', 'D TI PARASITOLOGY']                                                                                            138289\n",
    "# ['D ZE VIROLOGY', 'D QU MICROBIOLOGY', 'D TI PARASITOLOGY']                                                                                109803\n",
    "# ['D CO BIOCHEMICAL RESEARCH METHODS', 'D MC MATHEMATICAL & COMPUTATIONAL BIOLOGY']                                                          77687\n",
    "# ['D CQ BIOCHEMISTRY & MOLECULAR BIOLOGY', 'D CU BIOLOGY']                                                                                   56754\n",
    "# ['D PY MEDICINE, GENERAL & INTERNAL']                                                                                                       24506\n",
    "# ['D CO BIOCHEMICAL RESEARCH METHODS', 'D MC MATHEMATICAL & COMPUTATIONAL BIOLOGY', 'D PO MATHEMATICS, INTERDISCIPLINARY APPLICATIONS']        237\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"original size:\",df_merged.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### preselection by plos year\n",
    "print (years)\n",
    "preselection_df = df_merged[df_merged['plos_pub_year'].isin(years)]  \n",
    "print (\"size of preselection1 (by plos years):\",preselection_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### i remove self-citations\n",
    "if (string_self_ref==0) or  ( string_self_ref == 1 ): \n",
    "    preselection_df = preselection_df[preselection_df['self_citation']== string_self_ref ]  \n",
    "    if string_self_ref ==0:\n",
    "        string_self_ref = \", no self-cit\"\n",
    "    elif string_self_ref ==1:\n",
    "        string_self_ref = \", only self-cit\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### preselection by isolated or group references:\n",
    "if (string_isolated_ref==0) or  ( string_isolated_ref == 1 ): \n",
    "    preselection_df0 = preselection_df[preselection_df['isolated_citation']== string_isolated_ref ]  \n",
    "\n",
    "    if string_isolated_ref ==0:\n",
    "        string_isolated_ref = \", group ref\"\n",
    "    elif string_isolated_ref ==1:\n",
    "        string_isolated_ref = \", isolated ref\"\n",
    "else:    \n",
    "    preselection_df0 = preselection_df   \n",
    "    print (\"size of preselection1 (by isolated/group ref):\",preselection_df0.shape, string_isolated_ref)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### preselection by plos ONE subject category:\n",
    "if string_code_categ==\"\": \n",
    "    preselection_df111 = preselection_df0\n",
    "else:    \n",
    "    if \" \" not in string_code_categ:  # to include one single category\n",
    "        preselection_df111 = preselection_df0[preselection_df0['categ_codes'].str.contains(string_code_categ)]        \n",
    "        string_code_categ = \" \"+dict_code_categ[string_code_categ]  \n",
    "\n",
    "    else:  # if multiple codes-categories\n",
    "        list_codes = string_code_categ.split(\" \")\n",
    "        print (list_codes)\n",
    "\n",
    "        if len(list_codes) >= 2:              \n",
    "            preselection_df111 = preselection_df0[ preselection_df0['categ_codes'].str.contains('|'.join(list_codes)) ]  # to look for partial matches from a list of strings!!!!!\n",
    "\n",
    "\n",
    "        string_code_categ = \"\" \n",
    "        for code in list_codes:\n",
    "            string_code_categ += \"-\"+dict_code_categ[code] \n",
    "\n",
    "\n",
    "    print (\" size of preselection (by plos ONE subject category):\",preselection_df111.shape, string_code_categ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### preselection by plos journal:\n",
    "if string_journal==\"\": \n",
    "    preselection_df1 = preselection_df111\n",
    "else:    \n",
    "    preselection_df1 = preselection_df111[preselection_df111['plos_j1']== string_journal ]  \n",
    "print (\" size of preselection2 (by plos journal):\",preselection_df1.shape, string_journal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### preselection by plos field:\n",
    "if string_plos_field==\"\": \n",
    "    preselection_df2 = preselection_df1\n",
    "else:    \n",
    "    preselection_df2 = preselection_df1[preselection_df1['plos_field']== string_plos_field ]  \n",
    "print (\" size of preselection2 (by plos field):\",preselection_df2.shape, string_plos_field)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preselection_df3 = preselection_df2\n",
    "\n",
    "\n",
    "N_plos=len(preselection_df3.paper_UT.unique())        ## this values are overall, for the title   \n",
    "N_all=len(preselection_df3)\n",
    "\n",
    "\n",
    "\n",
    "fig_font_colors=''\n",
    "\n",
    "\n",
    "\n",
    "if v1_string ==  'cite_count'  or       v1_string ==  'log_num_cit_ref'   or v1_string == 'log2_num_cit_ref':\n",
    "\n",
    "\n",
    "\n",
    "    string_age_selection=''\n",
    "\n",
    "    ##### preselection only young/old references:        \n",
    "    if string_references_age == \"young\":\n",
    "        time_window = 1\n",
    "        string_age_selection=\"only young references from >=\"+ str((min(years)-time_window))\n",
    "        preselection_df3 = preselection_df2[preselection_df2['ref_pub_year'] >= (min(years)-time_window) ]   \n",
    "        print (\"  size of preselection3 (only young references):\",preselection_df3.shape, string_age_selection)\n",
    "\n",
    "    elif string_references_age == \"old\":\n",
    "        time_window = 10\n",
    "        string_age_selection=\"only old references from <=\"+str((min(years)-time_window))\n",
    "        preselection_df3 = preselection_df2[preselection_df2['ref_pub_year'] <= (min(years)-time_window) ]   \n",
    "        print (\"  size of preselection3 (only young references):\",preselection_df3.shape,string_age_selection )\n",
    "\n",
    "    else:\n",
    "        string_age_selection=\"young&old\"       \n",
    "        print (\"  No preselection by age of references:\",preselection_df3.shape )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    N_plos=len(preselection_df3.paper_UT.unique())        ## this values are overall, for the title   \n",
    "    N_all=len(preselection_df3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   # fig_colorscale = [[0, '#ffece6'], [1, '#ff0000']]   # if i give it a min and a max colors in HEX, it creates a gradient from one to another\n",
    "    fig_font_colors = ['#ff0000', '#ffece6']      # same for the annotation of the boxes (to make sure they are readable)\n",
    "\n",
    "    \n",
    "#     factor_color_rescale =.3   \n",
    "\n",
    "#     fig_colorscale=[[0.0*factor_color_rescale, '#ffffff'],\\\n",
    "#                            [0.1*factor_color_rescale, '#d9f2d9'],\\\n",
    "#                            [0.2*factor_color_rescale, '#c6ecc6'],\\\n",
    "#                            [0.3*factor_color_rescale, '#b3e6b3'],\\\n",
    "#                            [0.4*factor_color_rescale, '#8cd98c'], \\\n",
    "#                            [0.5*factor_color_rescale, '#66cc66'], \\\n",
    "#                            [0.6*factor_color_rescale, '#53c653'], \\\n",
    "#                            [0.7*factor_color_rescale, '#40bf40'],\\\n",
    "#                            [0.75*factor_color_rescale, '#39ac39'],\\\n",
    "#                            [0.8*factor_color_rescale, '#339933'],\\\n",
    "#                            [0.85*factor_color_rescale, '#2d862d'],\\\n",
    "#                            [0.9*factor_color_rescale, '#267326'],\\\n",
    "#                            [1.0, '#000000']]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    fig_colorscale = \"Reds\"\n",
    "    fig_title_plot = \"Median (final) number of citations of references in \"+string_journal+string_plos_field+\"<br> papers from \"+str(years)+\", \"+string_age_selection+string_isolated_ref+string_self_ref+string_code_categ+\"<br>Number of occurrences: \"+str(N_all)#+\",   Number plos: \"+str(N_plos)\n",
    "    fig_filename =   '../plots/annotated-heatmap_median_citations_of_references_for_sections_and_fract_subsection_by_citations_of_plos'\n",
    "\n",
    "    if  v1_string ==  'log_num_cit_ref' :\n",
    "        fig_title_plot = \"Median log10 of (final) number of citations of references in \"+string_journal+string_plos_field+\"<br> papers from \"+str(years)+\", \"+string_age_selection+string_isolated_ref+string_self_ref+string_code_categ+\"<br>Number of occurrences: \"+str(N_all)#+\",   Number plos: \"+str(N_plos)\n",
    "    elif  v1_string ==  'log2_num_cit_ref' :\n",
    "        fig_title_plot = \"Median log2 of (final) number of citations of references in \"+string_journal+string_plos_field+\"<br> papers from \"+str(years)+\", \"+string_age_selection+string_isolated_ref+string_self_ref+string_code_categ+\"<br>Number of occurrences: \"+str(N_all)#+\",   Number plos: \"+str(N_plos)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "elif v1_string =='ref_pub_year':\n",
    "    fig_colorscale = \"Viridis\"\n",
    "    fig_title_plot = \"Median age of references in \"+string_journal+string_plos_field+\"<br> papers from \"+str(years)+string_isolated_ref+string_self_ref+string_code_categ+\"<br>Number of occurrences: \"+str(N_all)#+\",   Number plos: \"+str(N_plos)\n",
    "    fig_filename = '../plots/annotated-heatmap_median_age_of_references_for_sections_and_fract_subsection_by_citations_of_plos'   \n",
    "    print (\"  No preselection by age of references:\",preselection_df3.shape )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "elif v1_string =='diff_year_plos_ref':\n",
    "\n",
    "#     factor_color_rescale =.6  \n",
    "\n",
    "#     fig_colorscale=[[0.0*factor_color_rescale, '#ffffff'],\\\n",
    "#                            [0.1*factor_color_rescale, '#d9f2d9'],\\\n",
    "#                            [0.2*factor_color_rescale, '#c6ecc6'],\\\n",
    "#                            [0.3*factor_color_rescale, '#b3e6b3'],\\\n",
    "#                            [0.4*factor_color_rescale, '#8cd98c'], \\\n",
    "#                            [0.5*factor_color_rescale, '#66cc66'], \\\n",
    "#                            [0.6*factor_color_rescale, '#53c653'], \\\n",
    "#                            [0.7*factor_color_rescale, '#40bf40'],\\\n",
    "#                            [0.75*factor_color_rescale, '#39ac39'],\\\n",
    "#                            [0.8*factor_color_rescale, '#339933'],\\\n",
    "#                            [0.85*factor_color_rescale, '#2d862d'],\\\n",
    "#                            [0.9*factor_color_rescale, '#267326'],\\\n",
    "#                           [1.0, '#000000']]\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    fig_colorscale = [[0, '#dcf0d2'], [1, '#205803']]   # if i give it a min and a max colors in HEX, it creates a gradient from one to another\n",
    "    fig_font_colors = ['#205803', '#dcf0d2']      # same for the annotation of the boxes (to make sure they are readable)\n",
    "    fig_title_plot = \"Median difference between publication year of plos and references in \"+string_journal+string_plos_field+\" papers from \"+str(years)+string_isolated_ref+string_self_ref+string_code_categ+\"<br>Number of occurrences: \"+str(N_all)#+\",   Number plos: \"+str(N_plos)\n",
    "    fig_filename = '../plots/annotated-heatmap_median_age_difference_plos_publ_year_vs_references_for_sections_and_subsect_by_citations_of_plos'\n",
    "\n",
    "    print (\"  No preselection by age of references:\",preselection_df3.shape )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"\\nTot # records included:\",len(preselection_df3),\"   # number of plos papers:\",len(preselection_df3.paper_UT.unique()), \"   # unique ref:\", len(preselection_df3.reference_UT.unique()),'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### i get the bins number of citation of the plos papers OJO!!!!! i want the same bins for all papers (so i calculate them before separating into sections but after all the preselections)\n",
    "\n",
    "#quantiles=sorted(list(df_plos[string_filtering_x].quantile(list_q).to_dict().items())) #mean 10.68 \n",
    "quantiles=sorted(list(preselection_df3[string_filtering_x].quantile(list_q).to_dict().items())) #mean 10.68 \n",
    "\n",
    "\n",
    "lista_bins_plos_citations=[]\n",
    "old_value=0\n",
    "for item in quantiles:\n",
    "    try:\n",
    "        pair=[old_value, int(item[1])]    \n",
    "    except:  # if it is a nan:\n",
    "        pair=[old_value, item[1]]\n",
    "\n",
    "    lista_bins_plos_citations.append(pair)\n",
    "\n",
    "    try:\n",
    "        old_value = int(item[1])\n",
    "    except:\n",
    "        old_value = item[1]\n",
    "\n",
    "print (lista_bins_plos_citations)\n",
    "\n",
    "\n",
    "\n",
    "### i modify the bins to separete the zero-one\n",
    "# lista_bins_plos_citations[0][0]=2       \n",
    "# lista_bins_plos_citations = [[0,2]] + lista_bins_plos_citations    \n",
    "#print (lista_bins_plos_citations)\n",
    "\n",
    "################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lista_titulos_sets = []\n",
    "\n",
    "\n",
    "\n",
    "lista_sections = [\"Introduction\",\"Methods\",\"Results\",\"Discussion\"]\n",
    "\n",
    "cont=0\n",
    "for item in lista_bins_plos_citations:\n",
    "\n",
    "    minimo = item[0]\n",
    "    maximo = item[1]\n",
    "\n",
    "\n",
    "    preselection_df4 = preselection_df3[(preselection_df3[string_filtering_x] >= minimo)  &  (preselection_df3[string_filtering_x] < maximo)]\n",
    "    #print (\"size of preselection3 (by cit bin plos):\",df_select.shape, item)\n",
    "\n",
    "\n",
    "\n",
    "    x1_All = list(preselection_df4[v1_string])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for string_section in lista_sections:\n",
    "\n",
    "\n",
    "        ##### preselection to include only occurences in a section of the paper\n",
    "        if  string_section == \"Introduction\":\n",
    "            section=0\n",
    "        elif  string_section == \"Methods\":\n",
    "            section=1\n",
    "        elif  string_section == \"Results\":\n",
    "            section=2\n",
    "        elif  string_section == \"Discussion\":\n",
    "            section=3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_select = preselection_df4[preselection_df4['regex_sect_index']== section]   \n",
    "        #print (\"size of preselection2 (by section):\",preselection_df3.shape, string_section)\n",
    "\n",
    "        x1 = list(df_select[v1_string])       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if cont ==0:            \n",
    "            #group=string_section+\" Bottom \"+str(int(100.*list_q[0]))+\"%\"  \n",
    "            group=string_section+\" Bottom\" \n",
    "        elif cont ==1:            \n",
    "            #group=string_section+\" \"+str(int(100.*list_q[0]+1))+\"%-\"+str(int(100.*list_q[-4]))+\"%\"         \n",
    "            group=string_section+\" Typical\"       \n",
    "        elif cont==2:\n",
    "             #group=string_section+\" \"+str(int(100.*list_q[1]+1))+\"%-\"+str(int(100.*list_q[-3]))+\"%\"     \n",
    "             group=string_section+\" Good\"    \n",
    "        elif cont==3: \n",
    "            #group=string_section+\" \"+str(int(100.*list_q[2]+1))+\"%-\"+str(int(100.*list_q[-2]))+\"%\"    \n",
    "            group=string_section+\" High\"\n",
    "        elif cont==4:\n",
    "            #group=string_section+\" Top \"+str(int(100.-100.*list_q[-2]))+\"%\"    \n",
    "            group=string_section+\" Top\"\n",
    "            \n",
    "            \n",
    "        lista_titulos_sets.append(group)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ######### i get also quantiles for each cell:    \n",
    "        list_quantiles_cell=[.25,.5,.75]\n",
    "\n",
    "        values_quantiles=list(df_select[v1_string].quantile(list_quantiles_cell))#sorted(list(df_select[v1_string].quantile(list_quantiles_cell).to_dict().items()))      \n",
    "\n",
    "        tupla=values_quantiles + [len(x1)]\n",
    "\n",
    "        dict_group_quantiles_size[group] = tupla\n",
    "\n",
    "        dict_group_subset_data[group]=x1\n",
    "\n",
    "\n",
    "\n",
    "    cont +=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ i also add the median values for the section across all data in the preselection\n",
    "for string_section in lista_sections:\n",
    "\n",
    "\n",
    "    if  string_section == \"Introduction\":\n",
    "        section=0\n",
    "    elif  string_section == \"Methods\":\n",
    "        section=1\n",
    "    elif  string_section == \"Results\":\n",
    "        section=2\n",
    "    elif  string_section == \"Discussion\":\n",
    "        section=3\n",
    "\n",
    "\n",
    "    df_select = preselection_df3[preselection_df3['regex_sect_index']== section]   \n",
    "\n",
    "    list_quantiles_cell=[.25,.5,.75]\n",
    "    values_quantiles=list(df_select[v1_string].quantile(list_quantiles_cell))#sorted(list(df_select[v1_string].quantile(list_quantiles_cell).to_dict().items()))      \n",
    "    tupla=values_quantiles + [len(df_select)]\n",
    "\n",
    "\n",
    "\n",
    "#     dict_group_quantiles_size[string_section+\" ALL PLOS\"]=tupla\n",
    "#     dict_group_subset_data[string_section+\" ALL PLOS\"]=x1_All    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########  I create the x, y, z lists of values for the heatmap\n",
    "\n",
    "lista_y=lista_sections\n",
    "#lista_x=[\" Bottom 30%\",\" 31% to 60%\",\" 61% to 90%\" ,\" 91% to 99%\",\" Top 1%\",\" ALL\"]\n",
    "#lista_bin_names=[\" ALL PLOS\",\" Bottom \"+str(int(100.*list_q[0]))+\"%\",\" \"+str(int(100.*list_q[0]+1))+\"% to \"+str(int(100.*list_q[-4]))+\"%\",\\\n",
    "              #   \" \"+str(int(100.*list_q[1]+1))+\"% to \"+str(int(100.*list_q[-3]))+\"%\" ,\" \"+str(int(100.*list_q[2]+1))+\"% to \"+str(int(100.*list_q[-2]))+\"%\",\" Top \"+str(int(100.-100.*list_q[-2]))+\"%\"]\n",
    "\n",
    "\n",
    "lista_bin_names=[\" Bottom\",\" Typical\",\" Good\",\" High\",\" Top\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lista_x=[\" Bottom 30%\",\" 31% to 60%\",\" 61% to 90%\" ,\" 91% to 99%\",\" Top 1%\"]   \n",
    "\n",
    "lista_x=lista_bin_names\n",
    "\n",
    "lista_z25=[]\n",
    "lista_z50=[]\n",
    "lista_z75=[]\n",
    "lista_z_sizes=[]\n",
    "\n",
    "for x_value in lista_x:    \n",
    "    aux_lista25=[]\n",
    "    aux_lista50=[]\n",
    "    aux_lista75=[]\n",
    "    aux_lista_sizes=[]\n",
    "\n",
    "    for y_value in lista_y:       \n",
    "\n",
    "        llave=y_value+x_value\n",
    "\n",
    "        try:\n",
    "            value=int(dict_group_quantiles_size[llave][0])\n",
    "        except:  # if it is a nan:\n",
    "            value=dict_group_quantiles_size[llave][0]\n",
    "        aux_lista25.append(value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            value=int(dict_group_quantiles_size[llave][1])\n",
    "        except:  # if it is a nan:\n",
    "            value=dict_group_quantiles_size[llave][1]\n",
    "        aux_lista50.append(value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            value=int(dict_group_quantiles_size[llave][2])\n",
    "        except:  # if it is a nan:\n",
    "            value=dict_group_quantiles_size[llave][2]\n",
    "        aux_lista75.append(value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        value_size=dict_group_quantiles_size[llave][3]\n",
    "        aux_lista_sizes.append(value_size)\n",
    "\n",
    "\n",
    "        #print (y_value,\" \",x_value, value, value_size)\n",
    "    lista_z25.append(aux_lista25)\n",
    "    lista_z50.append(aux_lista50)\n",
    "    lista_z75.append(aux_lista75)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lista_z_sizes.append(aux_lista_sizes)\n",
    "\n",
    "\n",
    "\n",
    "# print (\"lista values 25%-quantile:\",lista_z25)\n",
    "# print (\"lista sizes\",lista_z_sizes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lista_text_z=[]\n",
    "for i in range(len(lista_z_sizes)):\n",
    "    aux=[]\n",
    "    for j in range(len(lista_z_sizes[0])):\n",
    "        #value=str(lista_z25[i][j])+\"-<b>\"+str(lista_z50[i][j])+\"</b>-\"+str(lista_z75[i][j])+\"<br>(\"+str(lista_z_sizes[i][j])+\")\"            #\"Median:\"+str(lista_z[i][j])+\"<br> N:\"+str(lista_z_sizes[i][j])\n",
    "        value=str(lista_z25[i][j])+\"-<b>\"+str(lista_z50[i][j])+\"</b>-\"+str(lista_z75[i][j])+\"<br>(\"+str(format(lista_z_sizes[i][j], ',d'))+\")\"            #\"Median:\"+str(lista_z[i][j])+\"<br> N:\"+str(lista_z_sizes[i][j])\n",
    "\n",
    "\n",
    "\n",
    "        aux.append(value)\n",
    "    lista_text_z.append(aux)\n",
    "# print (lista_text_z)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### using a different library\n",
    "path=   '/home/staff/julia/at_Northwestern/In_Text_Citations/In-Text-Citations-New/plots/'\n",
    "\n",
    "\n",
    "fig = ff.create_annotated_heatmap(z=lista_z50, x=lista_sections, y=lista_bin_names, annotation_text=lista_text_z, colorscale=fig_colorscale, font_colors=fig_font_colors,showscale=True, colorbar=dict(title=colorbar_string, titleside='right' ,ticks='outside'),)#, reversescale=True)\n",
    "\n",
    "#fig = ff.create_annotated_heatmap(z=lista_z50, x=lista_sections, y=lista_bin_names,  colorscale=fig_colorscale, font_colors=fig_font_colors,showscale=True)#, reversescale=True)\n",
    "fig.layout.title = \"\"# fig_title_plot\n",
    "\n",
    "fig['layout']['xaxis']['side'] = 'bottom'\n",
    "fig.layout.xaxis.update({'title': 'Section'})\n",
    "\n",
    "\n",
    "fig.layout.yaxis.update({'title': 'Impact Group'})\n",
    "if v1_string ==  'cite_count'  :\n",
    "    if string_references_age == \"young\":  \n",
    "        fig.layout.yaxis.update({'title': ''})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font_gral=25  # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "fig['layout']['font']['size'] = font_gral\n",
    "\n",
    "      \n",
    "if v1_string ==  'cite_count'  :\n",
    "    if string_references_age == \"young\":  \n",
    "        #fig.layout.update({'title': '$d, r \\\\text{ (solar radius)}$'})\n",
    "        fig['layout']['title'] = \"Young references\"\n",
    "    elif string_references_age == \"old\":  \n",
    "        fig.layout.update({'title': 'Old references'})\n",
    "\n",
    "    fig.layout.update({'font': dict(size=25)})\n",
    "\n",
    "# fig.layout.yaxis.update({'title': 'Citation percentile of plos paper'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font_gral=55  # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "fig['layout']['font']['size'] = font_gral\n",
    "\n",
    "\n",
    "# Altering x axis\n",
    "#fig['layout']['xaxis']['tickfont']['family'] = 'Gill Sans MT'\n",
    "fig['layout']['xaxis']['tickangle'] = 0\n",
    "fig['layout']['yaxis']['tickangle'] = -90\n",
    "fig['layout']['xaxis']['titlefont']['size'] = font_gral + 20\n",
    "fig['layout']['yaxis']['titlefont']['size'] = font_gral\n",
    "\n",
    "fig['layout']['xaxis']['tickfont']['size'] = font_gral -7 \n",
    "fig['layout']['yaxis']['tickfont']['size'] = font_gral -15\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig['layout']['margin']=dict(\n",
    "        l=200,\n",
    "       # r=50,\n",
    "        b=150,\n",
    "        t=top_space,\n",
    "        pad=15\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  annotations=[\n",
    "#         dict(\n",
    "#             x=-.05,\n",
    "#             y=1.05,\n",
    "#             xref='paper',\n",
    "#             yref='paper',\n",
    "#             text=text_abc,\n",
    "#             showarrow=False,\n",
    "#             font=dict(               \n",
    "#                 size=80,  \n",
    "#                 color='black'\n",
    "#             ),\n",
    "           \n",
    "#         )\n",
    "#     ],\n",
    "\n",
    "\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename=fig_filename ,image_width=2000, image_height=1200, filename=fig_filename+'.html', validate=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# old, age >=15 years; Tot # records included: 88209    # number of plos papers: 12895    # unique ref: 61867 \n",
    "# young, age <=2 years;  Tot # records included: 104113    # number of plos papers: 13442    # unique ref: 66644 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "######################################################3\n",
    "########################################################\n",
    "\n",
    "\n",
    "##############  I RUN THE TESTS FOR THE COMPARISON OF ALL PAIRS OF SUB-SETS:  (all pair-wise comparison cells in figure 2b, and 3a, 2b)\n",
    "\n",
    "#####  mann-whitney U   test\n",
    "\n",
    "\n",
    "\n",
    "lista_indeces = [[1,1],[1,2],[1,3],[1,4],\\\n",
    "                 [2,1],[2,2],[2,3],[2,4],\\\n",
    "                 [3,1],[3,2],[3,3],[3,4],\\\n",
    "                 [4,1],[4,2],[4,3],[4,4],\\\n",
    "                 [5,1],[5,2],[5,3],[5,4]]\n",
    "\n",
    "#fig_colorscale=  [ [0., '#f2f2f2'], [threshold_zero,'#cce6ff'], [0.9999, '#0059b3'], [1.,'#bdbdbd']]# '#ffffff']]  0: white,  .99999: blue,  1: grey\n",
    "fig_colorscale=  [ [0., '#0059b3'], [.5,'#c7dcf1'], [1.,'#bdbdbd']] #  0 or anything significant: blue,   .5 or anithing NON signif: light-blue,     1: grey\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lista_bin_names = [\"Bottom\",\"Typical\",\"Good\",\"High\",\"Top\"]\n",
    "lista_sections  =  ['Intro', 'Methods', 'Results', 'Discussion']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tot_rows = 5\n",
    "tot_cols = 4  \n",
    "    \n",
    "test = \"MW\"  # KS to test if the distributions are different or  MW for testing just whether the medians are different \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "list_keys_macro = ['Introduction Top',    'Methods Top',    'Results Top',   'Discussion Top', \\\n",
    "                   'Introduction High',   'Methods High',  'Results High',  'Discussion High', \\\n",
    "                   'Introduction Good',   'Methods Good',   'Results Good',  'Discussion Good', \\\n",
    "                   'Introduction Typical', 'Methods Typical', 'Results Typical', 'Discussion Typical', \\\n",
    "                   'Introduction Bottom',  'Methods Bottom',  'Results Bottom', 'Discussion Bottom']\n",
    "    \n",
    "      \n",
    "list_keys_heatmap = ['Introduction Bottom', 'Methods Bottom',  'Results Bottom', 'Discussion Bottom',\\\n",
    "                     'Introduction Typical', 'Methods Typical', 'Results Typical', 'Discussion Typical',\\\n",
    "                     'Introduction Good',   'Methods Good',   'Results Good',  'Discussion Good', \\\n",
    "                     'Introduction High',   'Methods High',  'Results High',  'Discussion High', \\\n",
    "                     'Introduction Top',   'Methods Top',    'Results Top',   'Discussion Top'  ]\n",
    "\n",
    "\n",
    "### i apply the bonferroni correction:  new p-_value_threshold  required for significance = old_p_value /Number of comparisons = 0.001 / (20*19/2)     \n",
    "    \n",
    "threshold_zero = 0.0001 / (float(len(list_keys_macro))*float(len(list_keys_macro)-1)/2.)    # to round up to zero the very small p_values\n",
    "\n",
    "\n",
    "\n",
    "# lista_titulos_sets  (from the previous cell)\n",
    "\n",
    "# ['Introduction Bottom',\n",
    "#  'Methods Bottom',\n",
    "#  'Results Bottom',\n",
    "#  'Discussion Bottom',\n",
    "#  'Introduction Typical',\n",
    "#  'Methods Typical',\n",
    "#  'Results Typical',\n",
    "#  'Discussion Typical',\n",
    "#  'Introduction Good',\n",
    "#  'Methods Good',\n",
    "#  'Results Good',\n",
    "#  'Discussion Good',\n",
    "#  'Introduction High',\n",
    "#  'Methods High',\n",
    "#  'Results High',\n",
    "#  'Discussion High',\n",
    "#  'Introduction Top',\n",
    "#  'Methods Top',\n",
    "#  'Results Top',\n",
    "#  'Discussion Top']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lista_tot_datos=[]\n",
    "\n",
    "total_cont =0\n",
    "for i in list_keys_macro:\n",
    "    lista_listas=[]\n",
    "    aux_lista=[]\n",
    "    cont=1\n",
    "   \n",
    "    for j in list_keys_heatmap:\n",
    "             \n",
    "        set1 = dict_group_subset_data[i]\n",
    "        set2 = dict_group_subset_data[j]\n",
    "        \n",
    "        if test == \"KS\":\n",
    "            p_value = stats.ks_2samp(set1, set2)[1] \n",
    "        elif test == \"MW\":\n",
    "            p_value = stats.mannwhitneyu(set1, set2,  alternative='two-sided')[1]  \n",
    "        \n",
    "        \n",
    "        if p_value <= threshold_zero:  #i round up to zero the very small p_values\n",
    "                p_value =0.\n",
    "                \n",
    "        else:\n",
    "            p_value = .5  ### I ONLY CARFE ABOUT WHETGER IT IS SIGNIFICANT OR NOT, I DONT CARE ABOUT THE EXACT P-VALUE ONCE IT IS NOT SIGNIFICANT\n",
    "                \n",
    "        if i == j:  # i single out manually the self comparison\n",
    "            p_value=1.001  \n",
    "            \n",
    "            \n",
    "            \n",
    "        aux_lista.append(p_value)\n",
    "        \n",
    "        cont +=1\n",
    "        \n",
    "        if cont > tot_cols:\n",
    "            lista_listas.append(aux_lista)                  \n",
    "            aux_lista=[]\n",
    "            cont=1\n",
    "            \n",
    "    \n",
    "    \n",
    "    total_cont +=1\n",
    "    lista_tot_datos.append(lista_listas)\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "### I create an empty plot\n",
    "fig_macro = None\n",
    "fig_macro = tools.make_subplots(rows=tot_rows, cols=tot_cols, shared_xaxes=True, shared_yaxes=True, vertical_spacing = 0.01, horizontal_spacing = 0.01,   )\n",
    "\n",
    "\n",
    "for i in range(len(lista_tot_datos)):\n",
    "    datos = lista_tot_datos[i]\n",
    "    \n",
    "    cont_rows = lista_indeces[i][0]\n",
    "    cont_cols = lista_indeces[i][1]\n",
    "    \n",
    "    trace1 = go.Heatmap(z=datos,\n",
    "                       x=lista_sections,\n",
    "                       y=lista_bin_names,                        \n",
    "                       colorscale = fig_colorscale,\n",
    "                       showscale=False,)\n",
    "                        #reversescale=True, )#    )\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # i add each plot\n",
    "    fig_macro.append_trace(trace1, cont_rows, cont_cols)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "fontsize=32 \n",
    "fig_macro['layout']['font'].update({'size': fontsize})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig_macro['layout']['margin'].update({'l': 250})   # i add extra space to the margins of the plots\n",
    "# fig_macro['layout']['margin'].update({'b': 150})  \n",
    "# fig_macro['layout']['margin'].update({'t': 50})   \n",
    "\n",
    "\n",
    "\n",
    "lista_bin_names = [\"Bottom\",\"Typical\",\"Good\",\"High\",\"Top\"]\n",
    "lista_sections  =  ['Introduction', 'Methods', 'Results', 'Discussion']\n",
    "\n",
    "\n",
    "\n",
    "# i use the axis title of the small plots as values of the axis of the macro plot\n",
    "fig_macro['layout']['xaxis1'].update(title=lista_sections[0])  \n",
    "fig_macro['layout']['xaxis2'].update(title=lista_sections[1])\n",
    "fig_macro['layout']['xaxis3'].update(title=lista_sections[2])\n",
    "fig_macro['layout']['xaxis4'].update(title=lista_sections[3])\n",
    "\n",
    "\n",
    "fig_macro['layout']['yaxis1'].update(title=lista_bin_names[4])   # ojo con el orden aqui!!\n",
    "fig_macro['layout']['yaxis2'].update(title=lista_bin_names[3])\n",
    "fig_macro['layout']['yaxis3'].update(title=lista_bin_names[2])\n",
    "fig_macro['layout']['yaxis4'].update(title=lista_bin_names[1])\n",
    "fig_macro['layout']['yaxis5'].update(title=lista_bin_names[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  annotations=[\n",
    "#         dict(\n",
    "#             x=-.05,\n",
    "#             y=1.05,\n",
    "#             xref='paper',\n",
    "#             yref='paper',\n",
    "#             text='(b)',\n",
    "#             showarrow=False,\n",
    "#             font=dict(               \n",
    "#                 size=80,  \n",
    "#                 color='black'\n",
    "#             ),\n",
    "           \n",
    "#         )\n",
    "#     ],\n",
    "   \n",
    "         \n",
    "         \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "offline.plot(fig_macro, auto_open=True, image = 'png', image_filename='multiplot_comparisons' ,image_width=3000, image_height=2200,\n",
    "              filename='../plots/multiplot_comparisons.html', validate=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
