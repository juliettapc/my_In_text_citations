{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#Due to leftoevererrors in Nathan's python installation, some cleaning up occurs here\n",
    "#sys.path.append(\"./code/\")\n",
    "#sys.path.remove('/usr/local/lib/python2.7/site-packages') \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import datetime\n",
    "import pickle\n",
    "import gzip\n",
    "import os,glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import random\n",
    "from  scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "import itertools\n",
    "#sys.path\n",
    "\n",
    "\n",
    "import regex as re\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='juliettapc', api_key='nM6iUdx6dGaOiPXQTwpP')   # go to: https://plot.ly/settings/api#/   for a new key if needed\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 1.27 s, total: 5.95 s\n",
      "Wall time: 16.5 s\n",
      "done loading pickles (5787634, 34)\n",
      "(156558, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence</th>\n",
       "      <th>reference_UT</th>\n",
       "      <th>reference_rank</th>\n",
       "      <th>regex_sect_index</th>\n",
       "      <th>cite_count</th>\n",
       "      <th>ref_pub_year</th>\n",
       "      <th>paper_cite_count</th>\n",
       "      <th>plos_pub_year</th>\n",
       "      <th>sect_char_pos</th>\n",
       "      <th>sect_char_total</th>\n",
       "      <th>...</th>\n",
       "      <th>plos_article_type</th>\n",
       "      <th>num_cit_young_ref_by2009</th>\n",
       "      <th>num_cit_young_ref_by2010</th>\n",
       "      <th>num_cit_young_ref_by2011</th>\n",
       "      <th>num_cit_young_ref_by2012</th>\n",
       "      <th>num_cit_young_ref_by2013</th>\n",
       "      <th>num_cit_young_ref_by2009after8</th>\n",
       "      <th>num_cit_young_ref_by2008after8</th>\n",
       "      <th>num_cit_young_ref_by2010after8</th>\n",
       "      <th>num_cit_young_ref_by2007after8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>494</td>\n",
       "      <td>5398</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>000263911400006</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>142</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>000289279600018</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>269</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>000289279600018</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3844</td>\n",
       "      <td>5398</td>\n",
       "      <td>...</td>\n",
       "      <td>@ Article</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   occurence     reference_UT  reference_rank  regex_sect_index  cite_count  \\\n",
       "0          1  A1995QY75100004               1                 0        60.0   \n",
       "1          2  A1995QY75100004               1                 3        60.0   \n",
       "4          1  000263911400006               3                 0         5.0   \n",
       "5          1  000289279600018               4                 0        29.0   \n",
       "6          3  000289279600018               4                 3        29.0   \n",
       "\n",
       "   ref_pub_year  paper_cite_count  plos_pub_year  sect_char_pos  \\\n",
       "0        1995.0                 2         2013.0            139   \n",
       "1        1995.0                 2         2013.0            494   \n",
       "4        2009.0                 2         2013.0            142   \n",
       "5        2011.0                 2         2013.0            269   \n",
       "6        2011.0                 2         2013.0           3844   \n",
       "\n",
       "   sect_char_total              ...               plos_article_type  \\\n",
       "0             4029              ...                       @ Article   \n",
       "1             5398              ...                       @ Article   \n",
       "4             4029              ...                       @ Article   \n",
       "5             4029              ...                       @ Article   \n",
       "6             5398              ...                       @ Article   \n",
       "\n",
       "  num_cit_young_ref_by2009 num_cit_young_ref_by2010  num_cit_young_ref_by2011  \\\n",
       "0                      NaN                      NaN                       NaN   \n",
       "1                      NaN                      NaN                       NaN   \n",
       "4                      0.0                      0.0                       NaN   \n",
       "5                      0.0                      0.0                       0.0   \n",
       "6                      0.0                      0.0                       0.0   \n",
       "\n",
       "   num_cit_young_ref_by2012  num_cit_young_ref_by2013  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "5                       3.0                       NaN   \n",
       "6                       3.0                       NaN   \n",
       "\n",
       "   num_cit_young_ref_by2009after8 num_cit_young_ref_by2008after8  \\\n",
       "0                             NaN                            NaN   \n",
       "1                             NaN                            NaN   \n",
       "4                             5.0                            5.0   \n",
       "5                            39.0                           39.0   \n",
       "6                            39.0                           39.0   \n",
       "\n",
       "   num_cit_young_ref_by2010after8 num_cit_young_ref_by2007after8  \n",
       "0                             NaN                            NaN  \n",
       "1                             NaN                            NaN  \n",
       "4                             5.0                            5.0  \n",
       "5                            39.0                           39.0  \n",
       "6                            39.0                           39.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                  \n",
    "\n",
    "####  NEW FILE INCLUDING EARLY CITATIONS OF YOUNG REFERENCES:   ../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit.pkl\n",
    "                                            \n",
    "#%time df_merged = pickle.load(open('../data/df_reference_cite_plos_merged_simplified_added_more_columns_no_self-cit_one_ref_per_sect_ONLY_ARTICLES.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "%time df_merged = pickle.load(open('../data/df_reference_cite_plos_no_self-cit_one_ref_per_sect_ONLY_ARTICLES_early_cit_and_after_accretion_time.pkl', 'rb'))\n",
    "print (\"done loading pickles\", df_merged.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_merged = df_merged[df_merged['cite_count'] != -1]   # i dont know why, but there are 7 occurrences with value -1\n",
    "\n",
    "\n",
    "\n",
    "plos_df = df_merged.drop_duplicates(subset=['paper_UT'])\n",
    "print (plos_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 466 ms, sys: 114 ms, total: 580 ms\n",
      "Wall time: 1.32 s\n",
      "done loading plos_df (156610, 87)\n",
      "df_merged (5787630, 58)\n",
      "(156558, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence</th>\n",
       "      <th>reference_UT</th>\n",
       "      <th>reference_rank</th>\n",
       "      <th>regex_sect_index</th>\n",
       "      <th>cite_count</th>\n",
       "      <th>ref_pub_year</th>\n",
       "      <th>paper_cite_count</th>\n",
       "      <th>plos_pub_year</th>\n",
       "      <th>sect_char_pos</th>\n",
       "      <th>sect_char_total</th>\n",
       "      <th>...</th>\n",
       "      <th>fract_old_ref_section6</th>\n",
       "      <th>fract_old_ref_section7</th>\n",
       "      <th>fract_young_ref_section0</th>\n",
       "      <th>fract_young_ref_section1</th>\n",
       "      <th>fract_young_ref_section2</th>\n",
       "      <th>fract_young_ref_section3</th>\n",
       "      <th>fract_young_ref_section4</th>\n",
       "      <th>fract_young_ref_section5</th>\n",
       "      <th>fract_young_ref_section6</th>\n",
       "      <th>fract_young_ref_section7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1995QY75100004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>000088374400026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>543</td>\n",
       "      <td>2207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>000313346100007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>591</td>\n",
       "      <td>2474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>000301376000017</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>762</td>\n",
       "      <td>2700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>000232311300030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>77</td>\n",
       "      <td>3195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     occurence     reference_UT  reference_rank  regex_sect_index  cite_count  \\\n",
       "0            1  A1995QY75100004               1                 0        60.0   \n",
       "31           1  000088374400026               1                 0       477.0   \n",
       "74           1  000313346100007               2                 0         6.0   \n",
       "85           1  000301376000017               2                 0        35.0   \n",
       "108          1  000232311300030               1                 0      1687.0   \n",
       "\n",
       "     ref_pub_year  paper_cite_count  plos_pub_year  sect_char_pos  \\\n",
       "0          1995.0                 2         2013.0            139   \n",
       "31         2000.0                 2         2015.0            543   \n",
       "74         2013.0                 1         2015.0            591   \n",
       "85         2012.0                 8         2012.0            762   \n",
       "108        2005.0                98         2008.0             77   \n",
       "\n",
       "     sect_char_total           ...            fract_old_ref_section6  \\\n",
       "0               4029           ...                               0.0   \n",
       "31              2207           ...                               0.0   \n",
       "74              2474           ...                               0.0   \n",
       "85              2700           ...                               0.0   \n",
       "108             3195           ...                               0.0   \n",
       "\n",
       "    fract_old_ref_section7 fract_young_ref_section0  fract_young_ref_section1  \\\n",
       "0                      0.0                 0.000000                       0.0   \n",
       "31                     0.0                 0.023256                       0.0   \n",
       "74                     0.0                 0.181818                       0.0   \n",
       "85                     0.0                 0.130435                       0.0   \n",
       "108                    0.0                 0.000000                       0.0   \n",
       "\n",
       "     fract_young_ref_section2  fract_young_ref_section3  \\\n",
       "0                         0.0                  0.032258   \n",
       "31                        0.0                  0.023256   \n",
       "74                        0.0                  0.090909   \n",
       "85                        0.0                  0.086957   \n",
       "108                       0.0                  0.040000   \n",
       "\n",
       "     fract_young_ref_section4 fract_young_ref_section5  \\\n",
       "0                         0.0                      0.0   \n",
       "31                        0.0                      0.0   \n",
       "74                        0.0                      0.0   \n",
       "85                        0.0                      0.0   \n",
       "108                       0.0                      0.0   \n",
       "\n",
       "     fract_young_ref_section6 fract_young_ref_section7  \n",
       "0                         0.0                      0.0  \n",
       "31                        0.0                      0.0  \n",
       "74                        0.0                      0.0  \n",
       "85                        0.0                      0.0  \n",
       "108                       0.0                      0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######  i create the new columns for fraction of references in each section (labelled 0 to 7)\n",
    "\n",
    "\n",
    "\n",
    "%time plos_df = pickle.load(open('../data/plos_paper_dataframe_ONLY_ARTICLES_num_ref_sect_young_old.pkl', 'rb'))\n",
    "print (\"done loading plos_df\", plos_df.shape)\n",
    "plos_df_simplified = plos_df[['paper_UT','num_ref_section0','num_ref_section1','num_ref_section2','num_ref_section3','num_ref_section4','num_ref_section5','num_ref_section6','num_ref_section7',\n",
    "    'fract_old_ref_section0', 'fract_old_ref_section1', 'fract_old_ref_section2', 'fract_old_ref_section3', 'fract_old_ref_section4', 'fract_old_ref_section5', 'fract_old_ref_section6', 'fract_old_ref_section7',\\\n",
    "    'fract_young_ref_section0', 'fract_young_ref_section1', 'fract_young_ref_section2', 'fract_young_ref_section3', 'fract_young_ref_section4', 'fract_young_ref_section5', 'fract_young_ref_section6', 'fract_young_ref_section7']]\n",
    "\n",
    "# print (\"plos_df_simplified\", plos_df_simplified.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_merged = pd.merge(df_merged, plos_df_simplified, on='paper_UT', how='left')\n",
    "df_merged = pd.merge(df_merged, plos_df_simplified, on='paper_UT', how='left')\n",
    "print (\"df_merged\", df_merged.shape)\n",
    "\n",
    "# df_merged[['paper_UT','reference_UT','regex_sect_index','eff_num_ref','num_ref_section0','num_ref_section1','num_ref_section2','num_ref_section3','num_ref_section4','num_ref_section5','num_ref_section6','num_ref_section7']].head(100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_records_one_ref_per_plos = df_merged.drop_duplicates(subset=['paper_UT'])\n",
    "print (df_records_one_ref_per_plos.shape)\n",
    "\n",
    "\n",
    "\n",
    "# df_records_one_ref_per_plos.rename(columns={'paper_cite_count_x': 'paper_cite_count', 'plos_pub_year_x': 'plos_pub_year', 'ref_pub_year_x':'ref_pub_year','regex_sect_index_x':'regex_sect_index', 'total_refs_x':'total_refs'}, inplace=True)\n",
    "# df_merged.rename(columns={'paper_cite_count_x': 'paper_cite_count', 'plos_pub_year_x': 'plos_pub_year', 'ref_pub_year_x':'ref_pub_year','regex_sect_index_x':'regex_sect_index', 'total_refs_x':'total_refs','reference_UT_x':'reference_UT','cite_count_x':'cite_count'}, inplace=True)\n",
    "\n",
    "\n",
    "sorted(df_records_one_ref_per_plos.columns)\n",
    "\n",
    "df_records_one_ref_per_plos.head()\n",
    "\n",
    "\n",
    "\n",
    "###OJO!!!!! FALTA POR HACER BIEN EL MERGE PARA EVITAR REPETICION DE COLUMNAS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2], [2, 8], [8, 25], [25, 79], [79, 1173]] (156558, 58)\n",
      "[0, 2] (156558, 58) (35805, 58) [[(0.25, 7.0), (0.5, 12.0), (0.75, 17.0)], [(0.25, 1.0), (0.5, 3.0), (0.75, 6.0)], [(0.25, 0.0), (0.5, 0.0), (0.75, 2.0)], [(0.25, 5.0), (0.5, 11.0), (0.75, 18.0)]]\n",
      "[12, 3, 0, 11] \n",
      " [[7, 12, 17], [1, 3, 6], [0, 0, 2], [5, 11, 18]] \n",
      "\n",
      "[2, 8] (156558, 58) (57980, 58) [[(0.25, 8.0), (0.5, 13.0), (0.75, 18.0)], [(0.25, 1.0), (0.5, 3.0), (0.75, 6.0)], [(0.25, 0.0), (0.5, 0.0), (0.75, 4.0)], [(0.25, 6.0), (0.5, 12.0), (0.75, 19.0)]]\n",
      "[13, 3, 0, 12] \n",
      " [[8, 13, 18], [1, 3, 6], [0, 0, 4], [6, 12, 19]] \n",
      "\n",
      "[8, 25] (156558, 58) (46718, 58) [[(0.25, 9.0), (0.5, 13.0), (0.75, 19.0)], [(0.25, 1.0), (0.5, 3.0), (0.75, 6.0)], [(0.25, 0.0), (0.5, 1.0), (0.75, 6.0)], [(0.25, 7.0), (0.5, 13.0), (0.75, 20.0)]]\n",
      "[13, 3, 1, 13] \n",
      " [[9, 13, 19], [1, 3, 6], [0, 1, 6], [7, 13, 20]] \n",
      "\n",
      "[25, 79] (156558, 58) (14457, 58) [[(0.25, 9.0), (0.5, 13.0), (0.75, 19.0)], [(0.25, 1.0), (0.5, 3.0), (0.75, 7.0)], [(0.25, 0.0), (0.5, 2.0), (0.75, 8.0)], [(0.25, 7.0), (0.5, 13.0), (0.75, 21.0)]]\n",
      "[13, 3, 2, 13] \n",
      " [[9, 13, 19], [1, 3, 7], [0, 2, 8], [7, 13, 21]] \n",
      "\n",
      "[79, 1173] (156558, 58) (1597, 58) [[(0.25, 8.0), (0.5, 12.0), (0.75, 19.0)], [(0.25, 1.0), (0.5, 3.0), (0.75, 7.0)], [(0.25, 0.0), (0.5, 3.0), (0.75, 9.0)], [(0.25, 5.0), (0.5, 11.0), (0.75, 19.0)]]\n",
      "[12, 3, 3, 11] \n",
      " [[8, 12, 19], [1, 3, 7], [0, 3, 9], [5, 11, 19]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[12, 3, 0, 11]\n",
      "[13, 3, 0, 12]\n",
      "[13, 3, 1, 13]\n",
      "[13, 3, 2, 13]\n",
      "[12, 3, 3, 11]\n",
      "\n",
      "\n",
      "\n",
      "['7-<b>12</b>-17', '1-<b>3</b>-6', '0-<b>0</b>-2', '5-<b>11</b>-18']\n",
      "['8-<b>13</b>-18', '1-<b>3</b>-6', '0-<b>0</b>-4', '6-<b>12</b>-19']\n",
      "['9-<b>13</b>-19', '1-<b>3</b>-6', '0-<b>1</b>-6', '7-<b>13</b>-20']\n",
      "['9-<b>13</b>-19', '1-<b>3</b>-7', '0-<b>2</b>-8', '7-<b>13</b>-21']\n",
      "['8-<b>12</b>-19', '1-<b>3</b>-7', '0-<b>3</b>-9', '5-<b>11</b>-19']\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]  [ (1,3) x3,y1 ]  [ (1,4) x4,y1 ]\n",
      "[ (2,1) x1,y2 ]  [ (2,2) x2,y2 ]  [ (2,3) x3,y2 ]  [ (2,4) x4,y2 ]\n",
      "[ (3,1) x1,y3 ]  [ (3,2) x2,y3 ]  [ (3,3) x3,y3 ]  [ (3,4) x4,y3 ]\n",
      "[ (4,1) x1,y4 ]  [ (4,2) x2,y4 ]  [ (4,3) x3,y4 ]  [ (4,4) x4,y4 ]\n",
      "[ (5,1) x1,y5 ]  [ (5,2) x2,y5 ]  [ (5,3) x3,y5 ]  [ (5,4) x4,y5 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Introduction Bottom', 'Methods Bottom', 'Results Bottom', 'Discussion Bottom', 'Introduction Typical', 'Methods Typical', 'Results Typical', 'Discussion Typical', 'Introduction Good', 'Methods Good', 'Results Good', 'Discussion Good', 'Introduction High', 'Methods High', 'Results High', 'Discussion High', 'Introduction Top', 'Methods Top', 'Results Top', 'Discussion Top'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FIGURE 2A, HEATMAP FOR NUMBER OF REFERENCES\n",
    "\n",
    "       \n",
    "\n",
    "lista_bin_names = [\"Bottom\", \"Typical\", \"Good\", \"High\", \"Top\"]\n",
    "lista_sections = [\"Introduction\", \"Methods\", \"Results\", \"Discussion\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_q=[0.3,0.6,.9,.99,1]    \n",
    "    \n",
    "#### i get the bins number of citation of the plos papers OJO!!!!! i want the same bins for all papers (so i calculate them before separating into sections but after all the preselections)\n",
    "\n",
    "quantiles=sorted(list(df_records_one_ref_per_plos['paper_cite_count'].quantile(list_q).to_dict().items())) #mean 10.68 \n",
    "\n",
    "\n",
    "dict_group_subset_data = {}\n",
    "lista_bins_plos_citations=[]\n",
    "old_value=0\n",
    "for item in quantiles:\n",
    "    try:\n",
    "        pair=[old_value, int(item[1])]    \n",
    "    except:  # if it is a nan:\n",
    "        pair=[old_value, item[1]]\n",
    "    \n",
    "    lista_bins_plos_citations.append(pair)\n",
    "    \n",
    "    try:\n",
    "        old_value = int(item[1])\n",
    "    except:\n",
    "        old_value = item[1]\n",
    "\n",
    "print (lista_bins_plos_citations, df_records_one_ref_per_plos.shape)\n",
    "\n",
    "\n",
    "lista_set_names = []\n",
    "\n",
    "lista_text_z = []\n",
    "list_of_lists =[]\n",
    "cont_citation_groups=0\n",
    "for pair_values in lista_bins_plos_citations:    # needs to correspond to    [\"Bottom\",\"Typical\",\"Good\",\"High\",\"Top\"]   \n",
    "    #print (\"-------\",pair_values, cont_citation_groups, lista_bin_names[cont_citation_groups])\n",
    "    \n",
    "    minimo = pair_values[0]\n",
    "    maximo = pair_values[1]   \n",
    "    \n",
    "    string_cit_group = lista_bin_names[cont_citation_groups]\n",
    "    cont_citation_groups += 1\n",
    "    \n",
    "\n",
    "    df_select = df_records_one_ref_per_plos[(df_records_one_ref_per_plos['paper_cite_count'] >= minimo)  &  (df_records_one_ref_per_plos['paper_cite_count'] < maximo)]            \n",
    "    \n",
    "    list_q_cell = [.25,.5,.75]\n",
    "    list_quantiles = []   # for [intro, methods, results, discussion]\n",
    "    for column in ['num_ref_section0', 'num_ref_section1', 'num_ref_section2', 'num_ref_section3']:   #  intro  methods results dicussion\n",
    "        quantiles_cell_aux  = sorted(list(df_select[column].quantile(list_q_cell).to_dict().items())) #mean 10.68 \n",
    "        list_quantiles.append(quantiles_cell_aux)\n",
    "        \n",
    "                \n",
    "        x1 = list(df_select[column])\n",
    "        \n",
    "\n",
    "\n",
    "        if column == 'num_ref_section0':                        \n",
    "            group= \"Introduction \"+ string_cit_group       \n",
    "            \n",
    "        elif column ==  'num_ref_section1':                              \n",
    "            group= \"Methods \"+ string_cit_group                \n",
    "            \n",
    "        elif column ==  'num_ref_section2':               \n",
    "            group= \"Results \"+ string_cit_group          \n",
    "                \n",
    "        elif column ==  'num_ref_section3':               \n",
    "            group= \"Discussion \"+ string_cit_group                   \n",
    "            \n",
    "\n",
    "        lista_set_names.append(group)   \n",
    "\n",
    "        dict_group_subset_data[group]=x1\n",
    "        \n",
    "        \n",
    "       \n",
    "    print (pair_values, df_records_one_ref_per_plos.shape, df_select.shape, list_quantiles)\n",
    "   \n",
    "\n",
    "\n",
    "    #example   list_quantiles: [[(0.25, 7.0), (0.5, 12.0), (0.75, 17.0)],      [(0.25, 1.0), (0.5, 3.0), (0.75, 6.0)],      [(0.25, 0.0), (0.5, 0.0), (0.75, 2.0)],      [(0.25, 5.0), (0.5, 11.0), (0.75, 18.0)]]\n",
    "    \n",
    "    \n",
    "     \n",
    "    aux_list = [int(df_select.num_ref_section0.median()), int(df_select.num_ref_section1.median()), int(df_select.num_ref_section2.median()), int(df_select.num_ref_section3.median()) ]      # [intro, methods, results, discussion]\n",
    "    \n",
    "    \n",
    "    \n",
    "    lista_trios = []\n",
    "    for lista_pares in list_quantiles:\n",
    "        trio_valores = [ int(i[1]) for i in lista_pares]\n",
    "        lista_trios.append(trio_valores)\n",
    "    \n",
    "    print (aux_list,\"\\n\", lista_trios,'\\n')\n",
    "    list_of_lists.append(aux_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "                                                                                                                                          \n",
    "                                                                                                                                          \n",
    "    aux_lista_text_z =  [str(lista_trios[i]).replace('[','').replace(']','').replace(', ', '-')   + \"\"     for i in range(len(aux_list))]     # [intro, methods, results, discussion]\n",
    "  \n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    new_lista = [ item.split(\"-\")[0] + \"-<b>\"+ item.split(\"-\")[1] +\"</b>-\"+ item.split(\"-\")[2] for item in aux_lista_text_z  ]  # i add bold font for the median value of the trio\n",
    "    \n",
    "    \n",
    "    lista_text_z.append(new_lista)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "print (\"\\n\\n\")\n",
    "for lista in list_of_lists:\n",
    "    print (lista)\n",
    "\n",
    "print (\"\\n\\n\")\n",
    "for lista in lista_text_z:\n",
    "    print (lista)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_colorscale = [[0, '#ecbfe0'], [1, '#66475e']]   #   [[0, 'dcf0d2'], [1, '#205803']]   # if i give it a min and a max colors in HEX, it creates a gradient from one to another\n",
    "fig_font_colors = [ '#3c3636', '#efecee']   #['#205803', '#dcf0d2']      # same for the annotation of the boxes (to make sure they are readable)\n",
    "# fig_title_plot = \"Median difference between publication year of plos and references in \"+string_journal+string_plos_field+\" papers from \"+str(years)+string_isolated_ref+string_self_ref+string_code_categ+\"<br>Number of occurrences: \"+str(N_all)#+\",   Number plos: \"+str(N_plos)\n",
    "# fig_filename = '../plots/annotated-heatmap_median_age_difference_plos_publ_year_vs_references_for_sections_and_subsect_by_citations_of_plos'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colorbar_string = 'Number of References'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#fig = ff.create_annotated_heatmap(z=lista_z50, x=lista_sections, y=lista_bin_names, annotation_text=lista_text_z, colorscale=fig_colorscale, font_colors=fig_font_colors,showscale=True, colorbar=dict(title=colorbar_string, titleside='right' ),)#, reversescale=True)\n",
    "\n",
    "#colorscale='Viridis', \n",
    "\n",
    "\n",
    "    \n",
    "fig = ff.create_annotated_heatmap(z=list_of_lists, x=lista_sections, y=lista_bin_names, annotation_text=lista_text_z, colorscale=fig_colorscale, font_colors=fig_font_colors, showscale=True, colorbar=dict(title=colorbar_string, titleside='right', ticks='outside' ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#fig = ff.create_annotated_heatmap(z=lista_z50, x=lista_sections, y=lista_bin_names,  colorscale=fig_colorscale, font_colors=fig_font_colors,showscale=True)#, reversescale=True)\n",
    "fig.layout.title = \"\"# fig_title_plot\n",
    "\n",
    "fig['layout']['xaxis']['side'] = 'bottom'\n",
    "fig.layout.xaxis.update({'title': 'Section'})\n",
    "\n",
    "\n",
    "fig.layout.yaxis.update({'title': 'Impact Group'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "font_gral=25  # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "fig['layout']['font']['size'] = font_gral\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "font_gral=55  # 20 if i wanna see it on the browser, 40 if i care about the png output\n",
    "fig['layout']['font']['size'] = font_gral\n",
    "\n",
    "\n",
    "# Altering x axis7\n",
    "#fig['layout']['xaxis']['tickfont']['family'] = 'Gill Sans MT'\n",
    "fig['layout']['xaxis']['tickangle'] = 0\n",
    "fig['layout']['yaxis']['tickangle'] = -90\n",
    "fig['layout']['xaxis']['titlefont']['size'] = font_gral  #+10\n",
    "fig['layout']['yaxis']['titlefont']['size'] = font_gral\n",
    "\n",
    "fig['layout']['xaxis']['tickfont']['size'] = font_gral -7\n",
    "fig['layout']['yaxis']['tickfont']['size'] = font_gral -15\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig['layout']['margin']=dict(\n",
    "        l=200,\n",
    "       # r=50,\n",
    "        b=150,\n",
    "        t=0,\n",
    "        pad=15\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename='testing_annotated_heatmap_color' ,image_width=2000, image_height=1200, filename='testing_annotated_heatmap_color.html', validate=True)\n",
    "\n",
    "\n",
    "############################################\n",
    "########################################################################\n",
    "################################################\n",
    "\n",
    "\n",
    "## COPIED CELL!!##############  I RUN THE TESTS FOR THE COMPARISON OF ALL PAIRS OF SUB-SETS:  (all pair-wise comparison cells in figure 2A)\n",
    "\n",
    "#####  mann-whitney U   test\n",
    "\n",
    "\n",
    "\n",
    "lista_indeces = [[1,1],[1,2],[1,3],[1,4],\\\n",
    "                 [2,1],[2,2],[2,3],[2,4],\\\n",
    "                 [3,1],[3,2],[3,3],[3,4],\\\n",
    "                 [4,1],[4,2],[4,3],[4,4],\\\n",
    "                 [5,1],[5,2],[5,3],[5,4]]\n",
    "\n",
    "#fig_colorscale=  [ [0., '#f2f2f2'], [threshold_zero,'#cce6ff'], [0.9999, '#0059b3'], [1.,'#bdbdbd']]# '#ffffff']]  0: white,  .99999: blue,  1: grey\n",
    "fig_colorscale=  [ [0., '#0059b3'], [.5,'#c7dcf1'], [1.,'#bdbdbd']] #  0 or anything significant: blue,   .5 or anithing NON signif: light-blue,     1: grey\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lista_bin_names = [\"Bottom\",\"Typical\",\"Good\",\"High\",\"Top\"]\n",
    "lista_sections  =  ['Intro', 'Methods', 'Results', 'Discussion']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tot_rows = 5\n",
    "tot_cols = 4  \n",
    "    \n",
    "test = \"MW\"  # KS to test if the distributions are different or  MW for testing just whether the medians are different \n",
    "    \n",
    "\n",
    "### i apply the bonferroni correction:  new p-_value_threshold  required for significance = old_p_value /Number of comparisons = 0.001 / (20*19/2)     \n",
    "    \n",
    "\n",
    "\n",
    "list_keys_macro = ['Introduction Top',    'Methods Top',    'Results Top',   'Discussion Top', \\\n",
    "                   'Introduction High',   'Methods High',  'Results High',  'Discussion High', \\\n",
    "                   'Introduction Good',   'Methods Good',   'Results Good',  'Discussion Good', \\\n",
    "                   'Introduction Typical', 'Methods Typical', 'Results Typical', 'Discussion Typical', \\\n",
    "                   'Introduction Bottom',  'Methods Bottom',  'Results Bottom', 'Discussion Bottom']\n",
    "    \n",
    "      \n",
    "list_keys_heatmap = ['Introduction Bottom', 'Methods Bottom',  'Results Bottom', 'Discussion Bottom',\\\n",
    "                     'Introduction Typical', 'Methods Typical', 'Results Typical', 'Discussion Typical',\\\n",
    "                     'Introduction Good',   'Methods Good',   'Results Good',  'Discussion Good', \\\n",
    "                     'Introduction High',   'Methods High',  'Results High',  'Discussion High', \\\n",
    "                     'Introduction Top',   'Methods Top',    'Results Top',   'Discussion Top'  ]\n",
    "\n",
    "\n",
    "\n",
    "threshold_zero = 0.0001 / (float(len(list_keys_macro))*float(len(list_keys_macro)-1)/2.)    # to round up to zero the very small p_values\n",
    "\n",
    " \n",
    "#lista de sets en el orden obtenido en la celda anterior:\n",
    "\n",
    "# ['Introduction Bottom',\n",
    "#  'Methods Bottom',\n",
    "#  'Results Bottom',\n",
    "#  'Discussion Bottom',\n",
    "#  'Introduction Typical',\n",
    "#  'Methods Typical',\n",
    "#  'Results Typical',\n",
    "#  'Discussion Typical',\n",
    "#  'Introduction Good',\n",
    "#  'Methods Good',\n",
    "#  'Results Good',\n",
    "#  'Discussion Good',\n",
    "#  'Introduction High',\n",
    "#  'Methods High',\n",
    "#  'Results High',\n",
    "#  'Discussion High',\n",
    "#  'Introduction Top',\n",
    "#  'Methods Top',\n",
    "#  'Results Top',\n",
    "#  'Discussion Top']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lista_tot_datos=[]\n",
    "\n",
    "total_cont =0\n",
    "for i in list_keys_macro:\n",
    "    lista_listas=[]\n",
    "    aux_lista=[]\n",
    "    cont=1\n",
    "   \n",
    "    for j in list_keys_heatmap:\n",
    "             \n",
    "        set1 = dict_group_subset_data[i]\n",
    "        set2 = dict_group_subset_data[j]\n",
    "        \n",
    "        if test == \"KS\":\n",
    "            p_value = stats.ks_2samp(set1, set2)[1] \n",
    "        elif test == \"MW\":\n",
    "            p_value = stats.mannwhitneyu(set1, set2,  alternative='two-sided')[1]  \n",
    "        \n",
    "        \n",
    "        if p_value <= threshold_zero:  #i round up to zero the very small p_values\n",
    "                p_value =0.\n",
    "                \n",
    "        else:\n",
    "            p_value = .5  ### I ONLY CARFE ABOUT WHEThER IT IS SIGNIFICANT OR NOT, I DONT CARE ABOUT THE EXACT P-VALUE ONCE IT IS NOT SIGNIFICANT\n",
    "            \n",
    "            \n",
    "                \n",
    "        if i == j:  # i single out manually the self comparison\n",
    "            p_value=1.001  \n",
    "            \n",
    "            \n",
    "            \n",
    "        aux_lista.append(p_value)\n",
    "        \n",
    "        cont +=1\n",
    "        \n",
    "        if cont > tot_cols:\n",
    "            lista_listas.append(aux_lista)                  \n",
    "            aux_lista=[]\n",
    "            cont=1\n",
    "            \n",
    "    \n",
    "    \n",
    "    total_cont +=1\n",
    "    lista_tot_datos.append(lista_listas)\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "### I create an empty plot\n",
    "fig_macro = None\n",
    "fig_macro = tools.make_subplots(rows=tot_rows, cols=tot_cols, shared_xaxes=True, shared_yaxes=True, vertical_spacing = 0.01, horizontal_spacing = 0.01,   )\n",
    "\n",
    "\n",
    "for i in range(len(lista_tot_datos)):\n",
    "    datos = lista_tot_datos[i]\n",
    "    \n",
    "    cont_rows = lista_indeces[i][0]\n",
    "    cont_cols = lista_indeces[i][1]\n",
    "    \n",
    "    trace1 = go.Heatmap(z=datos,\n",
    "                       x=lista_sections,\n",
    "                       y=lista_bin_names,                        \n",
    "                       colorscale = fig_colorscale,\n",
    "                       showscale=False,)\n",
    "                        #reversescale=True, )#    )\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # i add each plot\n",
    "    fig_macro.append_trace(trace1, cont_rows, cont_cols)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "fontsize=32 \n",
    "fig_macro['layout']['font'].update({'size': fontsize})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_macro['layout']['margin'].update({'l': 250})   # i add extra space to the margins of the plots\n",
    "fig_macro['layout']['margin'].update({'b': 150})  \n",
    "fig_macro['layout']['margin'].update({'t': 50})   \n",
    "\n",
    "\n",
    "\n",
    "lista_bin_names = [\"Bottom\",\"Typical\",\"Good\",\"High\",\"Top\"]\n",
    "lista_sections  =  ['Introduction', 'Methods', 'Results', 'Discussion']\n",
    "\n",
    "\n",
    "\n",
    "# i use the axis title of the small plots as values of the axis of the macro plot\n",
    "fig_macro['layout']['xaxis1'].update(title=lista_sections[0])  \n",
    "fig_macro['layout']['xaxis2'].update(title=lista_sections[1])\n",
    "fig_macro['layout']['xaxis3'].update(title=lista_sections[2])\n",
    "fig_macro['layout']['xaxis4'].update(title=lista_sections[3])\n",
    "\n",
    "\n",
    "fig_macro['layout']['yaxis1'].update(title=lista_bin_names[4])   # ojo con el orden aqui!!\n",
    "fig_macro['layout']['yaxis2'].update(title=lista_bin_names[3])\n",
    "fig_macro['layout']['yaxis3'].update(title=lista_bin_names[2])\n",
    "fig_macro['layout']['yaxis4'].update(title=lista_bin_names[1])\n",
    "fig_macro['layout']['yaxis5'].update(title=lista_bin_names[0])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "offline.plot(fig_macro, auto_open=True, image = 'png', image_filename='multiplot_comparisons' ,image_width=3000, image_height=2200,\n",
    "              filename='multiplot_comparisons.html', validate=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dict_group_subset_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
